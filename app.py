import streamlit as st
import pandas as pd
import numpy as np
from datasets import load_dataset
import os
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def remove_tashkeel(text):
    """Remove Arabic diacritics for better text processing"""
    if not isinstance(text, str):
        return ""
    tashkeel_pattern = re.compile(r'[\u064B-\u065F\u0670]')
    return tashkeel_pattern.sub('', text)

def preprocess_arabic_text(text):
    """Enhanced Arabic text preprocessing"""
    if not isinstance(text, str):
        return ""
    
    # Remove diacritics
    text = remove_tashkeel(text)
    
    # Normalize Arabic letters
    text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
    text = re.sub(r'Ø©', 'Ù‡', text)
    text = re.sub(r'ÙŠ', 'Ù‰', text)
    
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

@st.cache_data
def load_quran_dataset_enhanced():
    """Enhanced Quran dataset loading with better error handling and caching"""
    
    try:
        # Show loading progress
        with st.spinner("ğŸ“– Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ± Ù…Ù† Hugging Face..."):
            
            # Set cache directory to avoid permission issues
            cache_dir = "./hf_cache"
            os.makedirs(cache_dir, exist_ok=True)
            
            # Load dataset with custom cache directory
            dataset = load_dataset(
                "MohamedRashad/Quran-Tafseer",
                cache_dir=cache_dir,
                trust_remote_code=True
            )
            
            # Convert to pandas DataFrame
            if 'train' in dataset:
                df = pd.DataFrame(dataset['train'])
            else:
                # If there's no 'train' split, use the first available split
                split_name = list(dataset.keys())[0]
                df = pd.DataFrame(dataset[split_name])
                st.info(f"Using dataset split: {split_name}")
            
            # Display initial dataset info
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ù…Ù† Hugging Face")
            
            # Show dataset columns for debugging
            st.info(f"Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {list(df.columns)}")
            
            # Handle different possible column names
            column_mapping = {
                'ayah': 'text',
                'verse': 'text', 
                'arabic': 'text',
                'quran_text': 'text',
                'verse_text': 'text',
                'surah_name': 'surah',
                'chapter': 'surah',
                'chapter_name': 'surah',
                'verse_number': 'ayah_number',
                'ayah_num': 'ayah_number',
                'verse_id': 'ayah_number',
                'tafsir': 'tafseer',
                'interpretation': 'tafseer',
                'explanation': 'tafseer'
            }
            
            # Apply column mapping
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns and new_col not in df.columns:
                    df[new_col] = df[old_col]
                    st.info(f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¹Ù…ÙˆØ¯ '{old_col}' Ø¥Ù„Ù‰ '{new_col}'")
            
            # Ensure required columns exist
            if 'text' not in df.columns:
                # Try to find any column that might contain the Quranic text
                possible_text_cols = ['ayah', 'verse', 'arabic', 'quran_text', 'verse_text']
                text_col = None
                for col in possible_text_cols:
                    if col in df.columns:
                        text_col = col
                        break
                
                if text_col:
                    df['text'] = df[text_col]
                    st.success(f"ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ '{text_col}' ÙƒÙ†Øµ Ø§Ù„Ø¢ÙŠØ§Øª")
                else:
                    st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ§Øª")
                    return pd.DataFrame()
            
            # Handle missing columns with defaults
            if 'surah' not in df.columns:
                df['surah'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                st.warning("âš ï¸ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø³ÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ - ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")
            
            if 'ayah_number' not in df.columns:
                df['ayah_number'] = range(1, len(df) + 1)
                st.warning("âš ï¸ Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ - ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªØ±Ù‚ÙŠÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠ")
            
            if 'tafseer' not in df.columns:
                df['tafseer'] = ''
                st.warning("âš ï¸ Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªÙØ³ÙŠØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ - Ø³ÙŠØªÙ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ ÙÙ‚Ø·")
            
            # Clean and preprocess text
            df['text'] = df['text'].fillna('').astype(str)
            df['clean_text'] = df['text'].apply(preprocess_arabic_text)
            
            # Preprocess tafseer if available
            if 'tafseer' in df.columns:
                df['tafseer'] = df['tafseer'].fillna('').astype(str)
                df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
            
            # Remove empty rows
            initial_count = len(df)
            df = df[df['clean_text'].str.strip() != ''].copy()
            df = df.dropna(subset=['text']).copy()
            final_count = len(df)
            
            if initial_count != final_count:
                st.info(f"ØªÙ… Ø¥Ø²Ø§Ù„Ø© {initial_count - final_count} Ø³Ø¬Ù„ ÙØ§Ø±Øº")
            
            # Reset index
            df = df.reset_index(drop=True)
            
            # Show sample data for verification
            st.markdown("### ğŸ” Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©:")
            sample_size = min(3, len(df))
            for i in range(sample_size):
                row = df.iloc[i]
                with st.expander(f"Ø§Ù„Ø¢ÙŠØ© {i+1}: {row.get('surah', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - Ø¢ÙŠØ© {row.get('ayah_number', i+1)}"):
                    st.write(f"**Ø§Ù„Ù†Øµ:** {row['text'][:100]}...")
                    if row.get('tafseer') and row['tafseer'].strip():
                        st.write(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {row['tafseer'][:100]}...")
            
            # Final statistics
            st.success(f"""
            âœ… **ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­:**
            - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¢ÙŠØ§Øª: {len(df):,}
            - Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©: {len(df['surah'].unique()) if 'surah' in df.columns else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}
            - Ø¢ÙŠØ§Øª Ø¨ØªÙØ³ÙŠØ±: {len(df[df['tafseer'].str.strip() != '']) if 'tafseer' in df.columns else 0}
            - Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ©: {df['text'].str.len().mean():.0f} Ø­Ø±Ù
            """)
            
            return df
            
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Hugging Face: {str(e)}")
        
        # Provide detailed error information
        st.markdown(f"""
        **ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£:**
        - Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£: {type(e).__name__}
        - Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {str(e)}
        
        **Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**
        1. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
        2. ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©: `MohamedRashad/Quran-Tafseer`
        3. Ø¬Ø±Ø¨ ØªØ«Ø¨ÙŠØª/ØªØ­Ø¯ÙŠØ« Ù…ÙƒØªØ¨Ø© datasets: `pip install --upgrade datasets`
        4. Ø§Ù…Ù†Ø­ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù„Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
        """)
        
        # Try to load a fallback local dataset if available
        return load_local_fallback()

def load_local_fallback():
    """Fallback to create sample data if Hugging Face is not available"""
    st.warning("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
    
    # Create comprehensive sample data for demonstration
    sample_data = {
        'text': [
            'Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„ÙÙ‘Ù‡Ù Ø±ÙØ¨ÙÙ‘ Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù',
            'Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯ÙÙ‘ÙŠÙ†Ù',
            'Ø¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù',
            'Ø§Ù‡Ù’Ø¯ÙÙ†ÙØ§ Ø§Ù„ØµÙÙ‘Ø±ÙØ§Ø·Ù Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙÙ‚ÙÙŠÙ…Ù',
            'ØµÙØ±ÙØ§Ø·Ù Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø£ÙÙ†Ù’Ø¹ÙÙ…Ù’ØªÙ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ØºÙÙŠÙ’Ø±Ù Ø§Ù„Ù’Ù…ÙØºÙ’Ø¶ÙÙˆØ¨Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ÙˆÙÙ„ÙØ§ Ø§Ù„Ø¶ÙÙ‘Ø§Ù„ÙÙ‘ÙŠÙ†Ù',
            'Ø§Ù„Ù…',
            'Ø°ÙÙ°Ù„ÙÙƒÙ Ø§Ù„Ù’ÙƒÙØªÙØ§Ø¨Ù Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù Û› ÙÙÙŠÙ‡Ù Û› Ù‡ÙØ¯Ù‹Ù‰ Ù„ÙÙ‘Ù„Ù’Ù…ÙØªÙÙ‘Ù‚ÙÙŠÙ†Ù',
            'Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù Ø¨ÙØ§Ù„Ù’ØºÙÙŠÙ’Ø¨Ù ÙˆÙÙŠÙÙ‚ÙÙŠÙ…ÙÙˆÙ†Ù Ø§Ù„ØµÙÙ‘Ù„ÙØ§Ø©Ù ÙˆÙÙ…ÙÙ…ÙÙ‘Ø§ Ø±ÙØ²ÙÙ‚Ù’Ù†ÙØ§Ù‡ÙÙ…Ù’ ÙŠÙÙ†ÙÙÙ‚ÙÙˆÙ†Ù'
        ],
        'surah': ['Ø§Ù„ÙØ§ØªØ­Ø©'] * 7 + ['Ø§Ù„Ø¨Ù‚Ø±Ø©'] * 3,
        'ayah_number': [1, 2, 3, 4, 5, 6, 7, 1, 2, 3],
        'tafseer': [
            'Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ø§ÙØªØªØ§Ø­ ÙƒÙ„ Ø³ÙˆØ±Ø© Ø¨Ø­Ù…Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„ÙŠÙ‡ØŒ ÙˆÙ‡ÙŠ Ø¢ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø±Ø¢Ù† ÙÙŠ Ø£ÙˆÙ„ ÙƒÙ„ Ø³ÙˆØ±Ø©',
            'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡: Ø§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø¨ØµÙØ§ØªÙ‡ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø© ÙˆØ£ÙØ¹Ø§Ù„Ù‡ Ø§Ù„Ø­Ù…ÙŠØ¯Ø©ØŒ ÙˆÙ‡Ùˆ Ø³Ø¨Ø­Ø§Ù†Ù‡ Ø§Ù„Ù…Ø³ØªØ­Ù‚ Ù„Ù„Ø­Ù…Ø¯ ÙˆØ§Ù„Ø«Ù†Ø§Ø¡',
            'Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø­Ø³Ù†Ù‰ØŒ Ø§Ù„Ø±Ø­Ù…Ù† Ø°Ùˆ Ø§Ù„Ø±Ø­Ù…Ø© Ø§Ù„ÙˆØ§Ø³Ø¹Ø©ØŒ ÙˆØ§Ù„Ø±Ø­ÙŠÙ… Ø°Ùˆ Ø§Ù„Ø±Ø­Ù…Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ†',
            'Ù…Ø§Ù„Ùƒ ÙŠÙˆÙ… Ø§Ù„Ø¯ÙŠÙ†: Ø§Ù„Ù„Ù‡ Ù‡Ùˆ Ø§Ù„Ù…Ø§Ù„Ùƒ Ø§Ù„Ù…ØªØµØ±Ù ÙŠÙˆÙ… Ø§Ù„Ù‚ÙŠØ§Ù…Ø©ØŒ ÙŠÙˆÙ… Ø§Ù„Ø¬Ø²Ø§Ø¡ ÙˆØ§Ù„Ø­Ø³Ø§Ø¨',
            'Ø¥ÙŠØ§Ùƒ Ù†Ø¹Ø¨Ø¯ ÙˆØ¥ÙŠØ§Ùƒ Ù†Ø³ØªØ¹ÙŠÙ†: Ø§Ù„ØªÙˆØ­ÙŠØ¯ ÙÙŠ Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ù†Ø©ØŒ ÙÙ†Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ­Ø¯Ù‡ ÙˆÙ†Ø³ØªØ¹ÙŠÙ† Ø¨Ù‡ ÙˆØ­Ø¯Ù‡',
            'Ø§Ù‡Ø¯Ù†Ø§ Ø§Ù„ØµØ±Ø§Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…: Ø¯Ø¹Ø§Ø¡ Ø¨Ø§Ù„Ù‡Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ… ÙˆÙ‡Ùˆ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…',
            'ØµØ±Ø§Ø· Ø§Ù„Ø°ÙŠÙ† Ø£Ù†Ø¹Ù…Øª Ø¹Ù„ÙŠÙ‡Ù…: Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡ ÙˆØ§Ù„ØµØ¯ÙŠÙ‚ÙŠÙ† ÙˆØ§Ù„Ø´Ù‡Ø¯Ø§Ø¡ ÙˆØ§Ù„ØµØ§Ù„Ø­ÙŠÙ†ØŒ ØºÙŠØ± Ø§Ù„Ù…ØºØ¶ÙˆØ¨ Ø¹Ù„ÙŠÙ‡Ù… ÙˆÙ‡Ù… Ø§Ù„ÙŠÙ‡ÙˆØ¯ØŒ ÙˆÙ„Ø§ Ø§Ù„Ø¶Ø§Ù„ÙŠÙ† ÙˆÙ‡Ù… Ø§Ù„Ù†ØµØ§Ø±Ù‰',
            'Ø§Ù„Ù…: Ù…Ù† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø·Ø¹Ø© ÙÙŠ Ø£ÙˆØ§Ø¦Ù„ Ø§Ù„Ø³ÙˆØ±ØŒ ÙˆØ§Ù„Ù„Ù‡ Ø£Ø¹Ù„Ù… Ø¨Ù…Ø±Ø§Ø¯Ù‡Ø§',
            'Ø°Ù„Ùƒ Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ø§ Ø±ÙŠØ¨ ÙÙŠÙ‡: Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ù„Ø§ Ø´Ùƒ ÙÙŠÙ‡ ÙˆÙ„Ø§ Ø±ÙŠØ¨ØŒ ÙˆÙ‡Ùˆ Ù‡Ø¯Ø§ÙŠØ© Ù„Ù„Ù…ØªÙ‚ÙŠÙ†',
            'Ø§Ù„Ø°ÙŠÙ† ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ø§Ù„ØºÙŠØ¨: ØµÙØ© Ø§Ù„Ù…ØªÙ‚ÙŠÙ† Ø£Ù†Ù‡Ù… ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ù…Ø§ ØºØ§Ø¨ Ø¹Ù†Ù‡Ù… Ù…Ù…Ø§ Ø£Ø®Ø¨Ø± Ø§Ù„Ù„Ù‡ Ø¨Ù‡ØŒ ÙˆÙŠÙ‚ÙŠÙ…ÙˆÙ† Ø§Ù„ØµÙ„Ø§Ø© ÙˆÙŠÙ†ÙÙ‚ÙˆÙ† Ù…Ù…Ø§ Ø±Ø²Ù‚Ù‡Ù… Ø§Ù„Ù„Ù‡'
        ]
    }
    
    df = pd.DataFrame(sample_data)
    df['clean_text'] = df['text'].apply(preprocess_arabic_text)
    df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
    
    st.warning("âš ï¸ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©. Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© datasets ÙˆØ§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª")
    
    return df

def test_dataset_loading():
    """Test function to verify dataset loading"""
    st.markdown("## ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    if st.button("ğŸ”„ Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Hugging Face"):
        df = load_quran_dataset_enhanced()
        
        if not df.empty:
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
            
            # Show detailed information
            st.markdown("### ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª", len(df))
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", len(df.columns))
            
            with col2:
                unique_surahs = len(df['surah'].unique()) if 'surah' in df.columns else 0
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
                has_tafseer = len(df[df['tafseer'].str.strip() != '']) if 'tafseer' in df.columns else 0
                st.metric("Ø¢ÙŠØ§Øª Ø¨ØªÙØ³ÙŠØ±", has_tafseer)
            
            with col3:
                avg_length = df['text'].str.len().mean() if 'text' in df.columns else 0
                st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ©", f"{avg_length:.0f}")
                
                if 'tafseer' in df.columns:
                    avg_tafseer_length = df['tafseer'].str.len().mean()
                    st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„ØªÙØ³ÙŠØ±", f"{avg_tafseer_length:.0f}")
            
            # Show column information
            st.markdown("### ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©:")
            for col in df.columns:
                non_null_count = df[col].notna().sum()
                st.write(f"- **{col}**: {non_null_count}/{len(df)} Ù‚ÙŠÙ…Ø© ØºÙŠØ± ÙØ§Ø±ØºØ©")
            
            # Show data types
            st.markdown("### ğŸ·ï¸ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
            st.write(df.dtypes)
            
            # Show sample rows
            st.markdown("### ğŸ‘€ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
            st.dataframe(df.head())
            
        else:
            st.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# Usage example
if __name__ == "__main__":
    st.set_page_config(
        page_title="Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†",
        page_icon="ğŸ“–",
        layout="wide"
    )
    
    st.title("ğŸ“– Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ±")
    
    test_dataset_loading()
