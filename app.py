import streamlit as st

# Page configuration MUST be first
st.set_page_config(
    page_title="ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ - Smart Quran Tafseer",
    page_icon="ğŸ“–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

import pandas as pd
import numpy as np
from datetime import datetime
import random
import pickle
from collections import Counter
import re

# Try to import optional dependencies
try:
    import joblib
    JOBLIB_AVAILABLE = True
except ImportError:
    JOBLIB_AVAILABLE = False
    st.warning("âš ï¸ Ù…ÙƒØªØ¨Ø© joblib ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù„Ù„ØªØ«Ø¨ÙŠØª: pip install joblib")

# Try to import advanced ML libraries
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    st.warning("âš ï¸ Ù…ÙƒØªØ¨Ø© scikit-learn ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù„Ù„ØªØ«Ø¨ÙŠØª: pip install scikit-learn")

try:
    from datasets import load_dataset
    DATASETS_AVAILABLE = True
except ImportError:
    DATASETS_AVAILABLE = False
    st.error("âŒ Ù…ÙƒØªØ¨Ø© datasets ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù„Ù„ØªØ«Ø¨ÙŠØª: pip install datasets")

try:
    from sentence_transformers import SentenceTransformer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    st.info("â„¹ï¸ Ù…ÙƒØªØ¨Ø© sentence-transformers ØºÙŠØ± Ù…Ø«Ø¨ØªØ© - Ù…ÙŠØ²Ø§Øª BERT Ù…Ø¹Ø·Ù„Ø©")

try:
    from gensim.models import Word2Vec
    GENSIM_AVAILABLE = True
except ImportError:
    GENSIM_AVAILABLE = False
    st.info("â„¹ï¸ Ù…ÙƒØªØ¨Ø© gensim ØºÙŠØ± Ù…Ø«Ø¨ØªØ© - Ù…ÙŠØ²Ø§Øª Word2Vec Ù…Ø¹Ø·Ù„Ø©")

import warnings
warnings.filterwarnings('ignore')

# Enhanced CSS with new branding for Quran Tafseer
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&family=Inter:wght@300;400;500;600;700&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=Noto+Kufi+Arabic:wght@300;400;500;600;700&display=swap');
    
    /* Advanced CSS Variables - Quran Theme Colors */
    :root {
        /* Primary Colors - Deep Green & Gold */
        --primary-50: #f0fdf4;
        --primary-100: #dcfce7;
        --primary-200: #bbf7d0;
        --primary-300: #86efac;
        --primary-400: #4ade80;
        --primary-500: #22c55e;
        --primary-600: #16a34a;
        --primary-700: #15803d;
        --primary-800: #166534;
        --primary-900: #14532d;
        
        /* Secondary Colors - Royal Blue */
        --secondary-50: #eff6ff;
        --secondary-100: #dbeafe;
        --secondary-200: #bfdbfe;
        --secondary-300: #93c5fd;
        --secondary-400: #60a5fa;
        --secondary-500: #3b82f6;
        --secondary-600: #2563eb;
        --secondary-700: #1d4ed8;
        --secondary-800: #1e40af;
        --secondary-900: #1e3a8a;
        
        /* Accent Colors - Golden */
        --accent-50: #fffbeb;
        --accent-100: #fef3c7;
        --accent-200: #fde68a;
        --accent-300: #fcd34d;
        --accent-400: #fbbf24;
        --accent-500: #f59e0b;
        --accent-600: #d97706;
        --accent-700: #b45309;
        --accent-800: #92400e;
        --accent-900: #78350f;
        
        /* Neutral Colors */
        --gray-50: #f9fafb;
        --gray-100: #f3f4f6;
        --gray-200: #e5e7eb;
        --gray-300: #d1d5db;
        --gray-400: #9ca3af;
        --gray-500: #6b7280;
        --gray-600: #4b5563;
        --gray-700: #374151;
        --gray-800: #1f2937;
        --gray-900: #111827;
        
        /* Spacing & Shadows */
        --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
        --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
        --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);
        --shadow-2xl: 0 25px 50px -12px rgb(0 0 0 / 0.25);
        
        --radius-sm: 6px;
        --radius-md: 8px;
        --radius-lg: 12px;
        --radius-xl: 16px;
        --radius-2xl: 20px;
        --radius-3xl: 24px;
    }
    
    .stApp {
        background: linear-gradient(135deg, 
            var(--primary-50) 0%, 
            var(--secondary-50) 25%,
            var(--accent-50) 50%,
            var(--primary-50) 75%,
            var(--secondary-50) 100%);
        min-height: 100vh;
        font-family: 'Inter', 'Noto Kufi Arabic', sans-serif;
    }
    
    /* Hide Streamlit defaults */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stDeployButton {visibility: hidden;}
    
    /* Enhanced Header for Quran Tafseer */
    .premium-header {
        background: linear-gradient(135deg, 
            rgba(22, 163, 74, 0.95) 0%,
            rgba(37, 99, 235, 0.9) 50%,
            rgba(217, 119, 6, 0.95) 100%);
        backdrop-filter: blur(20px) saturate(180%);
        color: white;
        padding: 3rem 0;
        margin: -1rem -1rem 3rem -1rem;
        box-shadow: var(--shadow-2xl);
        position: relative;
        overflow: hidden;
    }
    
    .header-content {
        max-width: 1400px;
        margin: 0 auto;
        padding: 0 2rem;
        text-align: center;
        position: relative;
        z-index: 1;
    }
    
    .header-title {
        font-size: 3.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
        font-family: 'Amiri', serif;
        text-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        background: linear-gradient(45deg, #ffffff, #f0f9ff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        line-height: 1.2;
    }
    
    /* Enhanced Cards */
    .premium-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(20px) saturate(180%);
        border-radius: var(--radius-2xl);
        box-shadow: var(--shadow-lg);
        border: 1px solid rgba(255, 255, 255, 0.5);
        margin-bottom: 2rem;
        overflow: hidden;
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        position: relative;
    }
    
    .premium-card:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: var(--shadow-2xl);
        border-color: rgba(22, 163, 74, 0.3);
    }
    
    /* Enhanced Arabic Text */
    .premium-arabic {
        font-family: 'Amiri', 'Noto Kufi Arabic', serif;
        font-size: 1.8rem;
        line-height: 2;
        color: var(--gray-800);
        margin: 2rem 0;
        text-align: right;
        direction: rtl;
        background: linear-gradient(135deg, 
            rgba(22, 163, 74, 0.05) 0%,
            rgba(255, 255, 255, 0.8) 50%,
            rgba(37, 99, 235, 0.05) 100%);
        padding: 2rem;
        border-radius: var(--radius-xl);
        border-right: 6px solid var(--primary-600);
        border-left: 2px solid var(--secondary-500);
        box-shadow: var(--shadow-md);
    }
    
    /* Tafseer specific styles */
    .tafseer-text {
        font-family: 'Noto Kufi Arabic', sans-serif;
        font-size: 1.2rem;
        line-height: 1.8;
        color: var(--gray-700);
        text-align: right;
        direction: rtl;
        background: var(--gray-50);
        padding: 1.5rem;
        border-radius: var(--radius-lg);
        border-right: 4px solid var(--accent-500);
        margin: 1rem 0;
    }
    
    .ayah-number {
        background: linear-gradient(135deg, var(--primary-600), var(--primary-700));
        color: white;
        padding: 6px 12px;
        border-radius: 50%;
        font-weight: bold;
        font-size: 0.9rem;
        display: inline-block;
        margin: 0 8px;
        min-width: 30px;
        text-align: center;
    }
    
    .surah-badge {
        background: linear-gradient(135deg, var(--secondary-600), var(--secondary-700));
        color: white;
        padding: 8px 16px;
        border-radius: var(--radius-3xl);
        font-weight: 600;
        font-size: 0.9rem;
        display: inline-block;
        margin: 8px 4px;
    }
    
    /* Model status indicators */
    .model-status {
        display: flex;
        gap: 1rem;
        justify-content: center;
        flex-wrap: wrap;
        margin: 1rem 0;
    }
    
    .model-badge {
        display: flex;
        align-items: center;
        gap: 6px;
        padding: 8px 16px;
        border-radius: var(--radius-3xl);
        font-size: 0.85rem;
        font-weight: 600;
        border: 2px solid transparent;
    }
    
    .model-active {
        background: linear-gradient(135deg, var(--primary-500), var(--primary-600));
        color: white;
        border-color: var(--primary-400);
    }
    
    .model-inactive {
        background: var(--gray-200);
        color: var(--gray-600);
        border-color: var(--gray-300);
    }
</style>
""", unsafe_allow_html=True)

# Enhanced utility functions for Arabic text processing
def remove_tashkeel(text):
    """Remove Arabic diacritics for better text processing"""
    if not isinstance(text, str):
        return ""
    tashkeel_pattern = re.compile(r'[\u064B-\u065F\u0670]')
    return tashkeel_pattern.sub('', text)

def preprocess_arabic_text(text):
    """Enhanced Arabic text preprocessing"""
    if not isinstance(text, str):
        return ""
    
    # Remove diacritics
    text = remove_tashkeel(text)
    
    # Normalize Arabic letters
    text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
    text = re.sub(r'Ø©', 'Ù‡', text)
    text = re.sub(r'ÙŠ', 'Ù‰', text)
    
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def create_sample_data():
    """Create comprehensive sample data for demonstration"""
    sample_data = {
        'text': [
            'Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„ÙÙ‘Ù‡Ù Ø±ÙØ¨ÙÙ‘ Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù',
            'Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯ÙÙ‘ÙŠÙ†Ù',
            'Ø¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù',
            'Ø§Ù‡Ù’Ø¯ÙÙ†ÙØ§ Ø§Ù„ØµÙÙ‘Ø±ÙØ§Ø·Ù Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙÙ‚ÙÙŠÙ…Ù',
            'ØµÙØ±ÙØ§Ø·Ù Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø£ÙÙ†Ù’Ø¹ÙÙ…Ù’ØªÙ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ØºÙÙŠÙ’Ø±Ù Ø§Ù„Ù’Ù…ÙØºÙ’Ø¶ÙÙˆØ¨Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ÙˆÙÙ„ÙØ§ Ø§Ù„Ø¶ÙÙ‘Ø§Ù„ÙÙ‘ÙŠÙ†Ù',
            'Ø§Ù„Ù…',
            'Ø°ÙÙ°Ù„ÙÙƒÙ Ø§Ù„Ù’ÙƒÙØªÙØ§Ø¨Ù Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù Û› ÙÙÙŠÙ‡Ù Û› Ù‡ÙØ¯Ù‹Ù‰ Ù„ÙÙ‘Ù„Ù’Ù…ÙØªÙÙ‘Ù‚ÙÙŠÙ†Ù',
            'Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù Ø¨ÙØ§Ù„Ù’ØºÙÙŠÙ’Ø¨Ù ÙˆÙÙŠÙÙ‚ÙÙŠÙ…ÙÙˆÙ†Ù Ø§Ù„ØµÙÙ‘Ù„ÙØ§Ø©Ù ÙˆÙÙ…ÙÙ…ÙÙ‘Ø§ Ø±ÙØ²ÙÙ‚Ù’Ù†ÙØ§Ù‡ÙÙ…Ù’ ÙŠÙÙ†ÙÙÙ‚ÙÙˆÙ†Ù',
            'ÙˆÙØ§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù Ø¨ÙÙ…ÙØ§ Ø£ÙÙ†Ø²ÙÙ„Ù Ø¥ÙÙ„ÙÙŠÙ’ÙƒÙ ÙˆÙÙ…ÙØ§ Ø£ÙÙ†Ø²ÙÙ„Ù Ù…ÙÙ† Ù‚ÙØ¨Ù’Ù„ÙÙƒÙ ÙˆÙØ¨ÙØ§Ù„Ù’Ø¢Ø®ÙØ±ÙØ©Ù Ù‡ÙÙ…Ù’ ÙŠÙÙˆÙ‚ÙÙ†ÙÙˆÙ†Ù',
            'Ø£ÙÙˆÙ„ÙÙ°Ø¦ÙÙƒÙ Ø¹ÙÙ„ÙÙ‰Ù° Ù‡ÙØ¯Ù‹Ù‰ Ù…ÙÙ‘Ù† Ø±ÙÙ‘Ø¨ÙÙ‘Ù‡ÙÙ…Ù’ Û– ÙˆÙØ£ÙÙˆÙ„ÙÙ°Ø¦ÙÙƒÙ Ù‡ÙÙ…Ù Ø§Ù„Ù’Ù…ÙÙÙ’Ù„ÙØ­ÙÙˆÙ†Ù',
            'Ø¥ÙÙ†ÙÙ‘ Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙƒÙÙÙØ±ÙÙˆØ§ Ø³ÙÙˆÙØ§Ø¡ÙŒ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ Ø£ÙØ£ÙÙ†Ø°ÙØ±Ù’ØªÙÙ‡ÙÙ…Ù’ Ø£ÙÙ…Ù’ Ù„ÙÙ…Ù’ ØªÙÙ†Ø°ÙØ±Ù’Ù‡ÙÙ…Ù’ Ù„ÙØ§ ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù',
            'Ø®ÙØªÙÙ…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø¹ÙÙ„ÙÙ‰Ù° Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙ…Ù’Ø¹ÙÙ‡ÙÙ…Ù’ Û– ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø£ÙØ¨Ù’ØµÙØ§Ø±ÙÙ‡ÙÙ…Ù’ ØºÙØ´ÙØ§ÙˆÙØ©ÙŒ Û– ÙˆÙÙ„ÙÙ‡ÙÙ…Ù’ Ø¹ÙØ°ÙØ§Ø¨ÙŒ Ø¹ÙØ¸ÙÙŠÙ…ÙŒ',
            'ÙˆÙÙ…ÙÙ†Ù Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù Ù…ÙÙ† ÙŠÙÙ‚ÙÙˆÙ„Ù Ø¢Ù…ÙÙ†ÙÙ‘Ø§ Ø¨ÙØ§Ù„Ù„ÙÙ‘Ù‡Ù ÙˆÙØ¨ÙØ§Ù„Ù’ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ù’Ø¢Ø®ÙØ±Ù ÙˆÙÙ…ÙØ§ Ù‡ÙÙ… Ø¨ÙÙ…ÙØ¤Ù’Ù…ÙÙ†ÙÙŠÙ†Ù',
            'ÙŠÙØ®ÙØ§Ø¯ÙØ¹ÙÙˆÙ†Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù ÙˆÙØ§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙÙ…ÙØ§ ÙŠÙØ®Ù’Ø¯ÙØ¹ÙÙˆÙ†Ù Ø¥ÙÙ„ÙÙ‘Ø§ Ø£ÙÙ†ÙÙØ³ÙÙ‡ÙÙ…Ù’ ÙˆÙÙ…ÙØ§ ÙŠÙØ´Ù’Ø¹ÙØ±ÙÙˆÙ†Ù',
            'ÙÙÙŠ Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ… Ù…ÙÙ‘Ø±ÙØ¶ÙŒ ÙÙØ²ÙØ§Ø¯ÙÙ‡ÙÙ…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ù…ÙØ±ÙØ¶Ù‹Ø§ Û– ÙˆÙÙ„ÙÙ‡ÙÙ…Ù’ Ø¹ÙØ°ÙØ§Ø¨ÙŒ Ø£ÙÙ„ÙÙŠÙ…ÙŒ Ø¨ÙÙ…ÙØ§ ÙƒÙØ§Ù†ÙÙˆØ§ ÙŠÙÙƒÙ’Ø°ÙØ¨ÙÙˆÙ†Ù',
            'ÙˆÙØ¥ÙØ°ÙØ§ Ù‚ÙÙŠÙ„Ù Ù„ÙÙ‡ÙÙ…Ù’ Ù„ÙØ§ ØªÙÙÙ’Ø³ÙØ¯ÙÙˆØ§ ÙÙÙŠ Ø§Ù„Ù’Ø£ÙØ±Ù’Ø¶Ù Ù‚ÙØ§Ù„ÙÙˆØ§ Ø¥ÙÙ†ÙÙ‘Ù…ÙØ§ Ù†ÙØ­Ù’Ù†Ù Ù…ÙØµÙ’Ù„ÙØ­ÙÙˆÙ†Ù',
            'Ø£ÙÙ„ÙØ§ Ø¥ÙÙ†ÙÙ‘Ù‡ÙÙ…Ù’ Ù‡ÙÙ…Ù Ø§Ù„Ù’Ù…ÙÙÙ’Ø³ÙØ¯ÙÙˆÙ†Ù ÙˆÙÙ„ÙÙ°ÙƒÙÙ† Ù„ÙÙ‘Ø§ ÙŠÙØ´Ù’Ø¹ÙØ±ÙÙˆÙ†Ù',
            'ÙˆÙØ¥ÙØ°ÙØ§ Ù‚ÙÙŠÙ„Ù Ù„ÙÙ‡ÙÙ…Ù’ Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙƒÙÙ…ÙØ§ Ø¢Ù…ÙÙ†Ù Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù Ù‚ÙØ§Ù„ÙÙˆØ§ Ø£ÙÙ†ÙØ¤Ù’Ù…ÙÙ†Ù ÙƒÙÙ…ÙØ§ Ø¢Ù…ÙÙ†Ù Ø§Ù„Ø³ÙÙ‘ÙÙÙ‡ÙØ§Ø¡Ù Û— Ø£ÙÙ„ÙØ§ Ø¥ÙÙ†ÙÙ‘Ù‡ÙÙ…Ù’ Ù‡ÙÙ…Ù Ø§Ù„Ø³ÙÙ‘ÙÙÙ‡ÙØ§Ø¡Ù ÙˆÙÙ„ÙÙ°ÙƒÙÙ† Ù„ÙÙ‘Ø§ ÙŠÙØ¹Ù’Ù„ÙÙ…ÙÙˆÙ†Ù'
        ],
        'surah': ['Ø§Ù„ÙØ§ØªØ­Ø©'] * 7 + ['Ø§Ù„Ø¨Ù‚Ø±Ø©'] * 13,
        'ayah_number': list(range(1, 8)) + list(range(1, 14)),
        'tafseer': [
            'Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ø§ÙØªØªØ§Ø­ ÙƒÙ„ Ø³ÙˆØ±Ø© Ø¨Ø­Ù…Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„ÙŠÙ‡ØŒ ÙˆÙ‡ÙŠ Ø¢ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø±Ø¢Ù† ÙÙŠ Ø£ÙˆÙ„ ÙƒÙ„ Ø³ÙˆØ±Ø© Ø¥Ù„Ø§ Ø¨Ø±Ø§Ø¡Ø©',
            'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø±Ø¨ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠÙ†: Ø§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø¨ØµÙØ§ØªÙ‡ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø© ÙˆØ£ÙØ¹Ø§Ù„Ù‡ Ø§Ù„Ø­Ù…ÙŠØ¯Ø©ØŒ ÙˆÙ‡Ùˆ Ø³Ø¨Ø­Ø§Ù†Ù‡ Ø§Ù„Ù…Ø³ØªØ­Ù‚ Ù„Ù„Ø­Ù…Ø¯ ÙˆØ§Ù„Ø«Ù†Ø§Ø¡ØŒ Ø±Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®Ù„ÙˆÙ‚Ø§Øª',
            'Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø­Ø³Ù†Ù‰ØŒ Ø§Ù„Ø±Ø­Ù…Ù† Ø°Ùˆ Ø§Ù„Ø±Ø­Ù…Ø© Ø§Ù„ÙˆØ§Ø³Ø¹Ø© Ø§Ù„ØªÙŠ ØªØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®Ù„ÙˆÙ‚Ø§ØªØŒ ÙˆØ§Ù„Ø±Ø­ÙŠÙ… Ø°Ùˆ Ø§Ù„Ø±Ø­Ù…Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ†',
            'Ù…Ø§Ù„Ùƒ ÙŠÙˆÙ… Ø§Ù„Ø¯ÙŠÙ†: Ø§Ù„Ù„Ù‡ Ù‡Ùˆ Ø§Ù„Ù…Ø§Ù„Ùƒ Ø§Ù„Ù…ØªØµØ±Ù ÙŠÙˆÙ… Ø§Ù„Ù‚ÙŠØ§Ù…Ø©ØŒ ÙŠÙˆÙ… Ø§Ù„Ø¬Ø²Ø§Ø¡ ÙˆØ§Ù„Ø­Ø³Ø§Ø¨ØŒ Ù„Ø§ Ù…Ù„Ùƒ ÙˆÙ„Ø§ Ù…ØªØµØ±Ù Ø³ÙˆØ§Ù‡',
            'Ø¥ÙŠØ§Ùƒ Ù†Ø¹Ø¨Ø¯ ÙˆØ¥ÙŠØ§Ùƒ Ù†Ø³ØªØ¹ÙŠÙ†: Ø§Ù„ØªÙˆØ­ÙŠØ¯ ÙÙŠ Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ù†Ø©ØŒ ÙÙ†Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ­Ø¯Ù‡ Ù„Ø§ Ø´Ø±ÙŠÙƒ Ù„Ù‡ØŒ ÙˆÙ†Ø³ØªØ¹ÙŠÙ† Ø¨Ù‡ ÙˆØ­Ø¯Ù‡ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù…ÙˆØ±Ù†Ø§',
            'Ø§Ù‡Ø¯Ù†Ø§ Ø§Ù„ØµØ±Ø§Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…: Ø¯Ø¹Ø§Ø¡ Ø¨Ø§Ù„Ù‡Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ… ÙˆÙ‡Ùˆ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ØŒ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙˆØ§Ø¶Ø­ Ø§Ù„Ø°ÙŠ Ù„Ø§ Ø§Ø¹ÙˆØ¬Ø§Ø¬ ÙÙŠÙ‡',
            'ØµØ±Ø§Ø· Ø§Ù„Ø°ÙŠÙ† Ø£Ù†Ø¹Ù…Øª Ø¹Ù„ÙŠÙ‡Ù…: Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡ ÙˆØ§Ù„ØµØ¯ÙŠÙ‚ÙŠÙ† ÙˆØ§Ù„Ø´Ù‡Ø¯Ø§Ø¡ ÙˆØ§Ù„ØµØ§Ù„Ø­ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† Ø£Ù†Ø¹Ù… Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡Ù…ØŒ ØºÙŠØ± Ø§Ù„Ù…ØºØ¶ÙˆØ¨ Ø¹Ù„ÙŠÙ‡Ù… ÙˆÙ‡Ù… Ø§Ù„ÙŠÙ‡ÙˆØ¯ØŒ ÙˆÙ„Ø§ Ø§Ù„Ø¶Ø§Ù„ÙŠÙ† ÙˆÙ‡Ù… Ø§Ù„Ù†ØµØ§Ø±Ù‰',
            'Ø§Ù„Ù…: Ù…Ù† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø·Ø¹Ø© ÙÙŠ Ø£ÙˆØ§Ø¦Ù„ Ø§Ù„Ø³ÙˆØ±ØŒ ÙˆØ§Ù„Ù„Ù‡ Ø£Ø¹Ù„Ù… Ø¨Ù…Ø±Ø§Ø¯Ù‡Ø§ØŒ ÙˆÙ‚ÙŠÙ„ Ø¥Ù†Ù‡Ø§ Ø£Ø³Ù…Ø§Ø¡ Ù„Ù„Ø³ÙˆØ± Ø£Ùˆ Ø£Ù‚Ø³Ø§Ù… Ø£Ù‚Ø³Ù… Ø§Ù„Ù„Ù‡ Ø¨Ù‡Ø§',
            'Ø°Ù„Ùƒ Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ø§ Ø±ÙŠØ¨ ÙÙŠÙ‡: Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ù„Ø§ Ø´Ùƒ ÙÙŠÙ‡ ÙˆÙ„Ø§ Ø±ÙŠØ¨ Ø£Ù†Ù‡ Ù…Ù† Ø¹Ù†Ø¯ Ø§Ù„Ù„Ù‡ØŒ ÙˆÙ‡Ùˆ Ù‡Ø¯Ø§ÙŠØ© ÙˆÙ†ÙˆØ± Ù„Ù„Ù…ØªÙ‚ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ®Ø§ÙÙˆÙ† Ø§Ù„Ù„Ù‡',
            'Ø§Ù„Ø°ÙŠÙ† ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ø§Ù„ØºÙŠØ¨: ØµÙØ© Ø§Ù„Ù…ØªÙ‚ÙŠÙ† Ø£Ù†Ù‡Ù… ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ù…Ø§ ØºØ§Ø¨ Ø¹Ù†Ù‡Ù… Ù…Ù…Ø§ Ø£Ø®Ø¨Ø± Ø§Ù„Ù„Ù‡ Ø¨Ù‡ ÙƒØ§Ù„Ù…Ù„Ø§Ø¦ÙƒØ© ÙˆØ§Ù„Ø¬Ù†Ø© ÙˆØ§Ù„Ù†Ø§Ø±ØŒ ÙˆÙŠÙ‚ÙŠÙ…ÙˆÙ† Ø§Ù„ØµÙ„Ø§Ø© Ø­Ù‚ Ø¥Ù‚Ø§Ù…ØªÙ‡Ø§ØŒ ÙˆÙŠÙ†ÙÙ‚ÙˆÙ† Ù…Ù…Ø§ Ø±Ø²Ù‚Ù‡Ù… Ø§Ù„Ù„Ù‡ ÙÙŠ Ø³Ø¨ÙŠÙ„Ù‡',
            'ÙˆØ§Ù„Ø°ÙŠÙ† ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ù…Ø§ Ø£Ù†Ø²Ù„ Ø¥Ù„ÙŠÙƒ: Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ† ÙŠØµØ¯Ù‚ÙˆÙ† Ø¨Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ù…Ù†Ø²Ù„ Ø¹Ù„Ù‰ Ù…Ø­Ù…Ø¯ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…ØŒ ÙˆØ¨Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙƒØ§Ù„ØªÙˆØ±Ø§Ø© ÙˆØ§Ù„Ø¥Ù†Ø¬ÙŠÙ„ØŒ ÙˆÙŠÙˆÙ‚Ù†ÙˆÙ† Ø¨Ø§Ù„Ø¢Ø®Ø±Ø© ÙˆÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ù‡Ø§ Ø¥ÙŠÙ…Ø§Ù†Ø§Ù‹ Ø¬Ø§Ø²Ù…Ø§Ù‹',
            'Ø£ÙˆÙ„Ø¦Ùƒ Ø¹Ù„Ù‰ Ù‡Ø¯Ù‰ Ù…Ù† Ø±Ø¨Ù‡Ù…: Ù‡Ø¤Ù„Ø§Ø¡ Ø§Ù„Ù…ØªØµÙÙˆÙ† Ø¨Ø§Ù„ØµÙØ§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø¹Ù„Ù‰ Ù†ÙˆØ± ÙˆØ¨ØµÙŠØ±Ø© Ù…Ù† Ø±Ø¨Ù‡Ù…ØŒ ÙˆÙ‡Ù… Ø§Ù„Ù…ÙÙ„Ø­ÙˆÙ† Ø§Ù„ÙØ§Ø¦Ø²ÙˆÙ† ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø¢Ø®Ø±Ø©',
            'Ø¥Ù† Ø§Ù„Ø°ÙŠÙ† ÙƒÙØ±ÙˆØ§ Ø³ÙˆØ§Ø¡ Ø¹Ù„ÙŠÙ‡Ù…: Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ† Ø§Ù„Ù…Ø¹Ø§Ù†Ø¯ÙˆÙ† Ù„Ø§ ÙŠÙ†ÙØ¹Ù‡Ù… Ø§Ù„Ø¥Ù†Ø°Ø§Ø± ÙˆÙ„Ø§ ØªØ±ÙƒÙ‡ØŒ ÙÙ‚Ø¯ Ø·Ø¨Ø¹ Ø§Ù„Ù„Ù‡ Ø¹Ù„Ù‰ Ù‚Ù„ÙˆØ¨Ù‡Ù… ÙÙ„Ø§ ÙŠØ¤Ù…Ù†ÙˆÙ†',
            'Ø®ØªÙ… Ø§Ù„Ù„Ù‡ Ø¹Ù„Ù‰ Ù‚Ù„ÙˆØ¨Ù‡Ù…: Ø·Ø¨Ø¹ Ø§Ù„Ù„Ù‡ Ø¹Ù„Ù‰ Ù‚Ù„ÙˆØ¨Ù‡Ù… ÙˆØ£Ø³Ù…Ø§Ø¹Ù‡Ù… ÙÙ„Ø§ ØªØ¹ÙŠ Ø§Ù„Ø­Ù‚ØŒ ÙˆØ¬Ø¹Ù„ Ø¹Ù„Ù‰ Ø£Ø¨ØµØ§Ø±Ù‡Ù… ØºØ´Ø§ÙˆØ© ÙÙ„Ø§ ØªØ¨ØµØ± Ø§Ù„Ù‡Ø¯Ù‰ØŒ ÙˆÙ„Ù‡Ù… Ø¹Ø°Ø§Ø¨ Ø¹Ø¸ÙŠÙ… ÙÙŠ Ø§Ù„Ø¢Ø®Ø±Ø©',
            'ÙˆÙ…Ù† Ø§Ù„Ù†Ø§Ø³ Ù…Ù† ÙŠÙ‚ÙˆÙ„ Ø¢Ù…Ù†Ø§ Ø¨Ø§Ù„Ù„Ù‡: ØµÙØ© Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ¸Ù‡Ø±ÙˆÙ† Ø§Ù„Ø¥ÙŠÙ…Ø§Ù† ÙˆÙŠØ¨Ø·Ù†ÙˆÙ† Ø§Ù„ÙƒÙØ±ØŒ ÙŠÙ‚ÙˆÙ„ÙˆÙ† Ø¢Ù…Ù†Ø§ Ø¨Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„ÙŠÙˆÙ… Ø§Ù„Ø¢Ø®Ø± ÙˆÙ…Ø§ Ù‡Ù… Ø¨Ù…Ø¤Ù…Ù†ÙŠÙ† Ø­Ù‚ÙŠÙ‚Ø©',
            'ÙŠØ®Ø§Ø¯Ø¹ÙˆÙ† Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø°ÙŠÙ† Ø¢Ù…Ù†ÙˆØ§: Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ† ÙŠØ­Ø³Ø¨ÙˆÙ† Ø£Ù†Ù‡Ù… ÙŠØ®Ø¯Ø¹ÙˆÙ† Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ† Ø¨Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ø¥ÙŠÙ…Ø§Ù†ØŒ ÙˆÙ…Ø§ ÙŠØ®Ø¯Ø¹ÙˆÙ† Ø¥Ù„Ø§ Ø£Ù†ÙØ³Ù‡Ù… ÙˆÙ…Ø§ ÙŠØ´Ø¹Ø±ÙˆÙ† Ø¨Ø°Ù„Ùƒ',
            'ÙÙŠ Ù‚Ù„ÙˆØ¨Ù‡Ù… Ù…Ø±Ø¶: ÙÙŠ Ù‚Ù„ÙˆØ¨ Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙŠÙ† Ù…Ø±Ø¶ Ø§Ù„Ø´Ùƒ ÙˆØ§Ù„Ù†ÙØ§Ù‚ØŒ ÙØ²Ø§Ø¯Ù‡Ù… Ø§Ù„Ù„Ù‡ Ù…Ø±Ø¶Ø§Ù‹ Ø¨Ø³Ø¨Ø¨ ÙƒÙØ±Ù‡Ù… ÙˆØ¹Ù†Ø§Ø¯Ù‡Ù…ØŒ ÙˆÙ„Ù‡Ù… Ø¹Ø°Ø§Ø¨ Ø£Ù„ÙŠÙ… Ø¨Ø³Ø¨Ø¨ ÙƒØ°Ø¨Ù‡Ù…',
            'ÙˆØ¥Ø°Ø§ Ù‚ÙŠÙ„ Ù„Ù‡Ù… Ù„Ø§ ØªÙØ³Ø¯ÙˆØ§: Ø¥Ø°Ø§ Ù†ÙÙ‡ÙŠ Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ† Ø¹Ù† Ø§Ù„Ø¥ÙØ³Ø§Ø¯ ÙÙŠ Ø§Ù„Ø£Ø±Ø¶ Ù‚Ø§Ù„ÙˆØ§ Ø¥Ù†Ù…Ø§ Ù†Ø­Ù† Ù…ØµÙ„Ø­ÙˆÙ†ØŒ ÙˆÙ‡Ù… ÙÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ù…ÙØ³Ø¯ÙˆÙ† ÙˆÙ„ÙƒÙ† Ù„Ø§ ÙŠØ¯Ø±ÙƒÙˆÙ† Ø°Ù„Ùƒ',
            'Ø£Ù„Ø§ Ø¥Ù†Ù‡Ù… Ù‡Ù… Ø§Ù„Ù…ÙØ³Ø¯ÙˆÙ†: ØªØ£ÙƒÙŠØ¯ Ø£Ù† Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙŠÙ† Ù‡Ù… Ø§Ù„Ù…ÙØ³Ø¯ÙˆÙ† Ø­Ù‚Ø§Ù‹ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ù… Ù„Ø§ ÙŠØ´Ø¹Ø±ÙˆÙ† Ø¨Ø¥ÙØ³Ø§Ø¯Ù‡Ù… ÙˆÙ„Ø§ ÙŠØ¯Ø±ÙƒÙˆÙ† Ø®Ø·Ø± Ø£ÙØ¹Ø§Ù„Ù‡Ù…',
            'ÙˆØ¥Ø°Ø§ Ù‚ÙŠÙ„ Ù„Ù‡Ù… Ø¢Ù…Ù†ÙˆØ§ ÙƒÙ…Ø§ Ø¢Ù…Ù† Ø§Ù„Ù†Ø§Ø³: Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙŠÙ† Ø£Ù† ÙŠØ¤Ù…Ù†ÙˆØ§ Ø¥ÙŠÙ…Ø§Ù†Ø§Ù‹ ØµØ§Ø¯Ù‚Ø§Ù‹ ÙƒØ¥ÙŠÙ…Ø§Ù† Ø§Ù„ØµØ­Ø§Ø¨Ø©ØŒ Ù‚Ø§Ù„ÙˆØ§ Ø£Ù†Ø¤Ù…Ù† ÙƒÙ…Ø§ Ø¢Ù…Ù† Ø§Ù„Ø³ÙÙ‡Ø§Ø¡ØŒ ÙˆØ§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø£Ù†Ù‡Ù… Ù‡Ù… Ø§Ù„Ø³ÙÙ‡Ø§Ø¡ ÙˆÙ„ÙƒÙ† Ù„Ø§ ÙŠØ¹Ù„Ù…ÙˆÙ†'
        ]
    }
    
    df = pd.DataFrame(sample_data)
    df['clean_text'] = df['text'].apply(preprocess_arabic_text)
    df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
    
    return df

@st.cache_data
def load_quran_dataset():
    """Load Quran dataset from Hugging Face or use sample data"""
    
    if not DATASETS_AVAILABLE:
        st.warning("âš ï¸ Ù…ÙƒØªØ¨Ø© datasets ØºÙŠØ± Ù…Ø«Ø¨ØªØ© - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
        return create_sample_data()
    
    try:
        with st.spinner("ğŸ“– Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ± Ù…Ù† Hugging Face..."):
            
            # Load dataset from Hugging Face
            dataset = load_dataset("MohamedRashad/Quran-Tafseer")
            
            # Convert to pandas DataFrame
            if 'train' in dataset:
                df = pd.DataFrame(dataset['train'])
            else:
                # Use first available split
                split_name = list(dataset.keys())[0]
                df = pd.DataFrame(dataset[split_name])
                st.info(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {split_name}")
            
            # Handle different column names
            column_mapping = {
                'ayah': 'text',
                'verse': 'text',
                'arabic': 'text',
                'surah_name': 'surah',
                'chapter': 'surah',
                'verse_number': 'ayah_number',
                'tafsir': 'tafseer'
            }
            
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns and new_col not in df.columns:
                    df[new_col] = df[old_col]
            
            # Ensure required columns exist
            if 'text' not in df.columns:
                st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                return create_sample_data()
            
            # Handle missing columns
            if 'surah' not in df.columns:
                df['surah'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            if 'ayah_number' not in df.columns:
                df['ayah_number'] = range(1, len(df) + 1)
            if 'tafseer' not in df.columns:
                df['tafseer'] = ''
            
            # Clean and preprocess
            df['text'] = df['text'].fillna('').astype(str)
            df['tafseer'] = df['tafseer'].fillna('').astype(str)
            df['clean_text'] = df['text'].apply(preprocess_arabic_text)
            df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
            
            # Remove empty rows
            df = df[df['clean_text'].str.strip() != ''].copy()
            df = df.dropna(subset=['text']).copy()
            df = df.reset_index(drop=True)
            
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df):,} Ø¢ÙŠØ© Ù…Ù† Hugging Face")
            return df
            
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Hugging Face: {e}")
        st.info("ğŸ”„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
        return create_sample_data()

def initialize_models():
    """Initialize available models with safe fallbacks"""
    models = {
        'bert_available': False,
        'w2v_available': False,
        'word2vec_available': False,
        'tfidf_available': SKLEARN_AVAILABLE,
        'bert_vectors': None,
        'w2v_vectors': None,
        'word2vec_model': None,
        'tfidf_vectorizer': None
    }
    
    # For now, we don't require the model files to exist
    # This allows the app to run with basic functionality
    
    return models

def simple_text_search(query, df, top_k=10):
    """Simple text-based search as fallback"""
    try:
        clean_query = preprocess_arabic_text(query).lower()
        if not clean_query.strip():
            return pd.DataFrame(), []
        
        # Calculate simple text similarity
        scores = []
        for _, row in df.iterrows():
            text = preprocess_arabic_text(str(row['text'])).lower()
            tafseer = preprocess_arabic_text(str(row.get('tafseer', ''))).lower()
            combined_text = text + ' ' + tafseer
            
            # Simple word matching score
            query_words = set(clean_query.split())
            text_words = set(combined_text.split())
            
            if query_words:
                overlap = len(query_words.intersection(text_words))
                score = overlap / len(query_words)
            else:
                score = 0
            
            scores.append(score)
        
        scores = np.array(scores)
        top_indices = scores.argsort()[-top_k:][::-1]
        top_scores = scores[top_indices]
        
        # Filter by minimum score
        valid_mask = top_scores > 0
        if not np.any(valid_mask):
            return pd.DataFrame(), []
        
        top_indices = top_indices[valid_mask]
        top_scores = top_scores[valid_mask]
        
        result_df = df.iloc[top_indices].copy()
        return result_df, top_scores.tolist()
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ: {e}")
        return pd.DataFrame(), []

def tfidf_search(query, df, top_k=10, vectorizer=None):
    """TF-IDF search with fallback to simple search"""
    try:
        if not SKLEARN_AVAILABLE:
            return simple_text_search(query, df, top_k)
        
        clean_query = preprocess_arabic_text(query)
        if not clean_query.strip():
            return pd.DataFrame(), []
        
        texts = df['clean_text'].fillna('').tolist()
        if not texts:
            return pd.DataFrame(), []
        
        # Create TF-IDF vectorizer
        vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 3),
            min_df=1,
            max_df=0.95
        )
        
        # Fit on corpus including query
        corpus = [clean_query] + texts
        tfidf_matrix = vectorizer.fit_transform(corpus)
        query_vector = tfidf_matrix[0]
        document_vectors = tfidf_matrix[1:]
        
        # Calculate similarities
        similarities = cosine_similarity(query_vector, document_vectors).flatten()
        
        # Get top results
        top_indices = similarities.argsort()[-top_k:][::-1]
        top_similarities = similarities[top_indices]
        
        # Filter by minimum similarity
        valid_mask = top_similarities > 0.01
        if not np.any(valid_mask):
            return pd.DataFrame(), []
        
        top_indices = top_indices[valid_mask]
        top_similarities = top_similarities[valid_mask]
        
        result_df = df.iloc[top_indices].copy()
        return result_df, top_similarities.tolist()
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¨Ù€ TF-IDF: {e}")
        return simple_text_search(query, df, top_k)

def display_ayah_card(row, similarity_score=None, model_types=None, card_id=None):
    """Enhanced display for Quran ayah with tafseer"""
    if card_id is None:
        card_id = f"ayah_{hash(str(row.get('text', ''))[:50])}"
    
    with st.container():
        st.markdown('<div class="premium-card">', unsafe_allow_html=True)
        st.markdown('<div style="padding: 2rem;">', unsafe_allow_html=True)
        
        # Header with surah and ayah info
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            surah_name = row.get('surah', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            ayah_number = row.get('ayah_number', '')
            
            st.markdown(f"""
            <div class="surah-badge">
                ğŸ“– Ø³ÙˆØ±Ø© {surah_name}
            </div>
            <span class="ayah-number">{ayah_number}</span>
            """, unsafe_allow_html=True)
        
        with col2:
            if similarity_score is not None:
                percentage = int(similarity_score * 100)
                color = "var(--primary-500)" if percentage > 70 else "var(--accent-500)" if percentage > 40 else "var(--secondary-500)"
                st.markdown(f"""
                <div style="
                    background: linear-gradient(135deg, {color}20, {color}10);
                    color: {color};
                    padding: 6px 12px;
                    border-radius: var(--radius-3xl);
                    text-align: center;
                    font-weight: 600;
                    border: 1px solid {color}30;
                ">
                    ğŸ¯ {percentage}%
                </div>
                """, unsafe_allow_html=True)
        
        with col3:
            if model_types:
                models_text = " + ".join(set(model_types)) if isinstance(model_types, list) else str(model_types)
                st.markdown(f"""
                <div style="
                    background: var(--gray-100);
                    color: var(--gray-700);
                    padding: 6px 12px;
                    border-radius: var(--radius-lg);
                    text-align: center;
                    font-size: 0.8rem;
                    font-weight: 500;
                ">
                    {models_text}
                </div>
                """, unsafe_allow_html=True)
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # Arabic text (Ayah)
        ayah_text = row.get('text', '')
        if ayah_text:
            st.markdown(f"""
            <div class="premium-arabic">
                {ayah_text}
            </div>
            """, unsafe_allow_html=True)
        
        # Tafseer (if available)
        tafseer_text = row.get('tafseer', '')
        if tafseer_text and tafseer_text.strip() and tafseer_text != 'nan':
            st.markdown("**ğŸ“š Ø§Ù„ØªÙØ³ÙŠØ±:**")
            st.markdown(f"""
            <div class="tafseer-text">
                {tafseer_text}
            </div>
            """, unsafe_allow_html=True)
        
        # Action buttons
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ“š Ø­ÙØ¸", key=f"save_{card_id}", use_container_width=True):
                if 'saved_ayahs' not in st.session_state:
                    st.session_state.saved_ayahs = []
                st.session_state.saved_ayahs.append(ayah_text)
                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¢ÙŠØ©!")
        
        with col2:
            if st.button("ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ø¢ÙŠØ©", key=f"copy_ayah_{card_id}", use_container_width=True):
                st.code(ayah_text, language="text")
                st.success("ğŸ“‹ ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø® Ø§Ù„Ù†Øµ Ø£Ø¹Ù„Ø§Ù‡!")
        
        with col3:
            if tafseer_text and st.button("ğŸ“ Ù†Ø³Ø® Ø§Ù„ØªÙØ³ÙŠØ±", key=f"copy_tafseer_{card_id}", use_container_width=True):
                st.code(tafseer_text, language="text")
                st.success("ğŸ“ ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø® Ø§Ù„ØªÙØ³ÙŠØ± Ø£Ø¹Ù„Ø§Ù‡!")
        
        with col4:
            if st.button("ğŸ” Ø¢ÙŠØ§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©", key=f"similar_{card_id}", use_container_width=True):
                st.session_state.find_similar_ayah = ayah_text
                st.rerun()
        
        st.markdown('</div></div>', unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state"""
    defaults = {
        'search_mode': 'tfidf',
        'saved_ayahs': [],
        'reading_history': [],
        'search_history': [],
        'daily_verses_read': 0,
        'total_verses_read': 0,
        'last_search_date': datetime.now().date(),
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def show_model_status(models):
    """Display current model status"""
    st.markdown('<div class="model-status">', unsafe_allow_html=True)
    
    # TF-IDF Status
    tfidf_class = "model-active" if models['tfidf_available'] else "model-inactive"
    tfidf_icon = "ğŸ“Š" if models['tfidf_available'] else "âŒ"
    st.markdown(f'''
    <div class="model-badge {tfidf_class}">
        <span>{tfidf_icon}</span>
        <span>TF-IDF Ù…ØªØ§Ø­</span>
    </div>
    ''', unsafe_allow_html=True)
    
    # Simple Search Status
    st.markdown(f'''
    <div class="model-badge model-active">
        <span>ğŸ”</span>
        <span>Ø¨Ø­Ø« Ù†ØµÙŠ Ù…ØªØ§Ø­</span>
    </div>
    ''', unsafe_allow_html=True)
    
    # Future Models
    st.markdown(f'''
    <div class="model-badge model-inactive">
        <span>ğŸ¤–</span>
        <span>BERT (Ù‚Ø±ÙŠØ¨Ø§Ù‹)</span>
    </div>
    ''', unsafe_allow_html=True)
    
    st.markdown(f'''
    <div class="model-badge model-inactive">
        <span>ğŸ§ </span>
        <span>Word2Vec (Ù‚Ø±ÙŠØ¨Ø§Ù‹)</span>
    </div>
    ''', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def show_search_tab(df, models):
    """Enhanced search tab"""
    st.markdown("### ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ±")
    
    # Search mode selection
    st.markdown("**ğŸ¯ Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š TF-IDF (Ø°ÙƒÙŠ)", 
                    key="mode_tfidf", 
                    use_container_width=True,
                    disabled=not models['tfidf_available'],
                    type="primary" if st.session_state.search_mode == 'tfidf' else "secondary"):
            st.session_state.search_mode = 'tfidf'
    
    with col2:
        if st.button("ğŸ” Ø¨Ø­Ø« Ù†ØµÙŠ (Ø¨Ø³ÙŠØ·)", 
                    key="mode_simple", 
                    use_container_width=True,
                    type="primary" if st.session_state.search_mode == 'simple' else "secondary"):
            st.session_state.search_mode = 'simple'
    
    # Search input
    col_search, col_button = st.columns([4, 1])
    
    with col_search:
        search_query = st.text_input(
            "",
            placeholder="Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ±... Ù…Ø«Ø§Ù„: 'Ø§Ù„ØµØ¨Ø±'ØŒ 'Ø§Ù„Ø±Ø­Ù…Ø©'ØŒ 'Ø§Ù„Ø¬Ù†Ø©'",
            key="main_search",
            label_visibility="collapsed"
        )
    
    with col_button:
        search_pressed = st.button("ğŸ” Ø¨Ø­Ø«", key="search_btn", use_container_width=True)
    
    # Advanced search options
    with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            max_results = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", 5, 50, 10, key="max_results")
        
        with col2:
            search_in_tafseer = st.checkbox("Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ± Ø£ÙŠØ¶Ø§Ù‹", value=True, key="search_tafseer")
    
    # Perform search
    if search_query and (search_pressed or search_query):
        # Add to search history
        if search_query not in st.session_state.search_history:
            st.session_state.search_history.insert(0, search_query)
            st.session_state.search_history = st.session_state.search_history[:20]
        
        with st.spinner(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            results_df = pd.DataFrame()
            similarities = []
            
            # Prepare search dataframe
            search_df = df.copy()
            if search_in_tafseer and 'tafseer' in df.columns:
                # Combine ayah and tafseer for search
                search_df['combined_text'] = (
                    search_df['clean_text'].fillna('') + ' ' + 
                    search_df.get('clean_tafseer', '').fillna('')
                )
                search_df['clean_text'] = search_df['combined_text']
            
            # Execute search based on selected mode
            if st.session_state.search_mode == 'tfidf' and models['tfidf_available']:
                results_df, similarities = tfidf_search(search_query, search_df, max_results)
                model_type = 'TF-IDF'
            else:
                results_df, similarities = simple_text_search(search_query, search_df, max_results)
                model_type = 'Ø¨Ø­Ø« Ù†ØµÙŠ'
            
            # Display results
            if not results_df.empty:
                st.success(f"ğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results_df)} Ù†ØªÙŠØ¬Ø©")
                
                # Results summary
                if similarities:
                    avg_similarity = np.mean(similarities) * 100
                    max_similarity = np.max(similarities) * 100
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©", f"{avg_similarity:.1f}%")
                    with col2:
                        st.metric("Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø©", f"{max_similarity:.1f}%")
                    with col3:
                        unique_surahs = len(results_df['surah'].unique())
                        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
                
                # Display results
                for idx, (_, row) in enumerate(results_df.iterrows()):
                    similarity = similarities[idx] if idx < len(similarities) else None
                    display_ayah_card(row, similarity, model_type, f"result_{idx}")
                    
            else:
                st.markdown("""
                <div style="
                    text-align: center;
                    padding: 3rem 2rem;
                    background: var(--gray-50);
                    border-radius: var(--radius-2xl);
                    border: 2px dashed var(--gray-300);
                    margin: 2rem 0;
                ">
                    <div style="font-size: 3rem; margin-bottom: 1rem; opacity: 0.5;">ğŸ”</div>
                    <h3 style="color: var(--gray-600); margin-bottom: 0.5rem;">Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬</h3>
                    <p style="color: var(--gray-500);">Ø¬Ø±Ø¨ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ ØºÙŠØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«</p>
                </div>
                """, unsafe_allow_html=True)
    
    # Quick search suggestions
    if not search_query:
        st.markdown("### ğŸš€ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
        
        suggestions = [
            "Ø§Ù„ØµØ¨Ø±", "Ø§Ù„Ø±Ø­Ù…Ø©", "Ø§Ù„Ø¬Ù†Ø©", 
            "Ø§Ù„ØªÙˆØ¨Ø©", "Ø§Ù„Ø¯Ø¹Ø§Ø¡", "Ø§Ù„Ø¹Ø¯Ù„",
            "Ø§Ù„ØµÙ„Ø§Ø©", "Ø§Ù„Ø£Ù…Ø§Ù†Ø©", "Ø§Ù„ØªÙ‚ÙˆÙ‰"
        ]
        
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 3]:
                if st.button(f"ğŸ” {suggestion}", key=f"suggestion_{i}", use_container_width=True):
                    st.session_state.main_search = suggestion
                    st.rerun()
        
        # Search history
        if st.session_state.search_history:
            st.markdown("### ğŸ“š Ø¢Ø®Ø± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø«")
            
            for i, query in enumerate(st.session_state.search_history[:5]):
                if st.button(f"ğŸ“– {query}", key=f"history_{i}", use_container_width=True):
                    st.session_state.main_search = query
                    st.rerun()

def show_saved_tab():
    """Show saved ayahs"""
    st.markdown("### ğŸ“š Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
    
    if not st.session_state.saved_ayahs:
        st.markdown("""
        <div style="
            text-align: center;
            padding: 3rem 2rem;
            background: var(--gray-50);
            border-radius: var(--radius-2xl);
            border: 2px dashed var(--gray-300);
            margin: 2rem 0;
        ">
            <div style="font-size: 3rem; margin-bottom: 1rem; opacity: 0.5;">ğŸ“š</div>
            <h3 style="color: var(--gray-600); margin-bottom: 0.5rem;">Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¢ÙŠØ§Øª Ù…Ø­ÙÙˆØ¸Ø©</h3>
            <p style="color: var(--gray-500);">Ø§Ø­ÙØ¸ Ø¢ÙŠØ§ØªÙƒ Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù„ØªØ¸Ù‡Ø± Ù‡Ù†Ø§</p>
        </div>
        """, unsafe_allow_html=True)
        return
    
    # Statistics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", len(st.session_state.saved_ayahs))
    with col2:
        st.metric("Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙŠÙˆÙ…", st.session_state.daily_verses_read)
    with col3:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø§Øª", st.session_state.total_verses_read)
    
    # Display saved ayahs
    st.markdown("### ğŸ“– Ø¢ÙŠØ§ØªÙƒ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
    
    for i, ayah in enumerate(st.session_state.saved_ayahs):
        st.markdown(f"""
        <div class="premium-card">
            <div style="padding: 2rem;">
                <div class="premium-arabic">{ayah}</div>
                <div style="margin-top: 1rem;">
                    <small style="color: var(--gray-500);">Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ {datetime.now().strftime('%Y-%m-%d')}</small>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)

def show_stats_tab(df, models):
    """Statistics tab"""
    st.markdown("### ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
    
    # Dataset statistics
    st.markdown("#### ğŸ“š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¢ÙŠØ§Øª", f"{len(df):,}")
    
    with col2:
        unique_surahs = len(df['surah'].unique())
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
    
    with col3:
        has_tafseer = len(df[df['tafseer'].notna() & (df['tafseer'] != '')])
        st.metric("Ø¢ÙŠØ§Øª Ø¨ØªÙØ³ÙŠØ±", f"{has_tafseer:,}")
    
    with col4:
        avg_length = df['text'].str.len().mean()
        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ©", f"{avg_length:.0f} Ø­Ø±Ù")
    
    # Model performance
    st.markdown("#### ğŸ¤– Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    show_model_status(models)
    
    # User statistics
    st.markdown("#### ğŸ‘¤ Ø¥Ø­ØµØ§Ø¦ÙŠØ§ØªÙƒ Ø§Ù„Ø´Ø®ØµÙŠØ©")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", len(st.session_state.saved_ayahs))
    
    with col2:
        st.metric("Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø«", len(st.session_state.search_history))
    
    with col3:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø§Øª", st.session_state.total_verses_read)

def show_about_tab():
    """About section"""
    st.markdown("### â„¹ï¸ Ø­ÙˆÙ„ ØªØ·Ø¨ÙŠÙ‚ ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ")
    
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, var(--primary-50), var(--secondary-50));
        padding: 2rem;
        border-radius: var(--radius-2xl);
        border: 1px solid var(--primary-200);
        margin: 2rem 0;
    ">
        <h4 style="color: var(--primary-700); margin-bottom: 1rem;">ğŸ¤– ØªØ·Ø¨ÙŠÙ‚ Ù…ØªØ·ÙˆØ± Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…</h4>
        <p style="color: var(--gray-700); line-height: 1.6;">
            ÙŠØ³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ·ÙˆØ±Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… ÙˆØªÙØ³ÙŠØ±Ù‡.
            ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TF-IDF.
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø© Ù…Ù† Hugging Face Dataset: MohamedRashad/Quran-Tafseer
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Technical details
    st.markdown("#### ğŸ› ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ” Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø«:**
        - **TF-IDF**: ØªØ­Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚
        - **Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ**: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
        - **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹
        """)
    
    with col2:
        st.markdown("""
        **ğŸ“š Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
        - Hugging Face Dataset: MohamedRashad/Quran-Tafseer
        - ØªÙØ³ÙŠØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…
        - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        """)
    
    # Installation guide
    st.markdown("#### ğŸ“¥ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
    
    requirements = """
streamlit>=1.28.0
pandas>=1.5.0
numpy>=1.21.0
datasets>=2.14.0
scikit-learn>=1.3.0
"""
    
    st.code(requirements, language="text")
    
    st.info("""
    ğŸ’¡ **Ù†ØµØ§Ø¦Ø­ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡:**
    - Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©
    - Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ± Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙˆØ³Ø¹
    - Ø§Ø­ÙØ¸ Ø¢ÙŠØ§ØªÙƒ Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù„Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
    - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ù„Ù„Ø§Ø³ØªÙƒØ´Ø§Ù
    """)

def main():
    """Main application"""
    # Initialize session state
    initialize_session_state()
    
    # Show loading message
    with st.spinner("ğŸš€ Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚..."):
        # Load data and models
        df = load_quran_dataset()
        models = initialize_models()
    
    if df.empty:
        st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†")
        st.stop()
    
    # Header
    st.markdown(f"""
    <div class="premium-header">
        <div class="header-content">
            <div style="margin-bottom: 1.5rem;">
                <div style="font-size: 4rem; margin-bottom: 1rem;">ğŸ“–</div>
            </div>
            <h1 class="header-title">ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</h1>
            <p style="font-size: 1.4rem; color: rgba(255, 255, 255, 0.95); margin-bottom: 1rem;">
                Smart Quran Tafseer with AI-Powered Search
            </p>
            <p style="color: rgba(255, 255, 255, 0.8); font-size: 1.1rem;">
                Ø¨Ø­Ø« Ø°ÙƒÙŠ ÙÙŠ {len(df):,} Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ© Ù…Ø¹ Ø§Ù„ØªÙØ³ÙŠØ±
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Show model status
    show_model_status(models)
    
    # Navigation
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ", "ğŸ“š Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", "ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "â„¹ï¸ Ø­ÙˆÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"])
    
    with tab1:
        show_search_tab(df, models)
    
    with tab2:
        show_saved_tab()
    
    with tab3:
        show_stats_tab(df, models)
    
    with tab4:
        show_about_tab()
    
    # Footer
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: var(--gray-500); padding: 2rem;">
        <p>ğŸ“– <strong>ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</strong> - ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ù€ â¤ï¸ Ù„Ø®Ø¯Ù…Ø© ÙƒØªØ§Ø¨ Ø§Ù„Ù„Ù‡</p>
        <p style="font-size: 0.9rem;">Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {datetime.now().strftime('%Y-%m-%d')}</p>
        <p style="font-size: 0.8rem;">Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: MohamedRashad/Quran-Tafseer Ø¹Ù„Ù‰ Hugging Face</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
