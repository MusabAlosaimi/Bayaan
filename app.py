import streamlit as st

# Page configuration MUST be first
st.set_page_config(
    page_title="ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ - Smart Quran Tafseer",
    page_icon="ğŸ“–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

import pandas as pd
import numpy as np
from datetime import datetime
import re
from collections import Counter

# Try to import optional dependencies
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    st.warning("âš ï¸ Ù…ÙƒØªØ¨Ø© scikit-learn ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù„Ù„ØªØ«Ø¨ÙŠØª: pip install scikit-learn")

try:
    from datasets import load_dataset
    DATASETS_AVAILABLE = True
except ImportError:
    DATASETS_AVAILABLE = False
    st.error("âŒ Ù…ÙƒØªØ¨Ø© datasets ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù„Ù„ØªØ«Ø¨ÙŠØª: pip install datasets")

import warnings
warnings.filterwarnings('ignore')

# Enhanced CSS
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&family=Inter:wght@300;400;500;600;700&display=swap');
    
    :root {
        --primary-600: #16a34a;
        --primary-700: #15803d;
        --secondary-600: #2563eb;
        --secondary-700: #1d4ed8;
        --accent-500: #f59e0b;
        --gray-50: #f9fafb;
        --gray-100: #f3f4f6;
        --gray-500: #6b7280;
        --gray-600: #4b5563;
        --gray-700: #374151;
        --gray-800: #1f2937;
    }
    
    .stApp {
        background: linear-gradient(135deg, #f0fdf4 0%, #eff6ff 50%, #fffbeb 100%);
        font-family: 'Inter', sans-serif;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stDeployButton {visibility: hidden;}
    
    .premium-header {
        background: linear-gradient(135deg, rgba(22, 163, 74, 0.95) 0%, rgba(37, 99, 235, 0.9) 50%, rgba(217, 119, 6, 0.95) 100%);
        color: white;
        padding: 3rem 0;
        margin: -1rem -1rem 3rem -1rem;
        text-align: center;
        border-radius: 0 0 20px 20px;
    }
    
    .header-title {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 1rem;
        font-family: 'Amiri', serif;
    }
    
    .premium-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.5);
    }
    
    .premium-arabic {
        font-family: 'Amiri', serif;
        font-size: 1.8rem;
        line-height: 2;
        color: var(--gray-800);
        text-align: right;
        direction: rtl;
        background: linear-gradient(135deg, rgba(22, 163, 74, 0.05) 0%, rgba(255, 255, 255, 0.8) 100%);
        padding: 2rem;
        border-radius: 15px;
        border-right: 6px solid var(--primary-600);
        margin: 1rem 0;
    }
    
    .tafseer-text {
        font-family: 'Amiri', serif;
        font-size: 1.2rem;
        line-height: 1.8;
        color: var(--gray-700);
        text-align: right;
        direction: rtl;
        background: var(--gray-50);
        padding: 1.5rem;
        border-radius: 10px;
        border-right: 4px solid var(--accent-500);
        margin: 1rem 0;
    }
    
    .ayah-number {
        background: linear-gradient(135deg, var(--primary-600), var(--primary-700));
        color: white;
        padding: 6px 12px;
        border-radius: 50%;
        font-weight: bold;
        font-size: 0.9rem;
        display: inline-block;
        margin: 0 8px;
        min-width: 30px;
        text-align: center;
    }
    
    .surah-badge {
        background: linear-gradient(135deg, var(--secondary-600), var(--secondary-700));
        color: white;
        padding: 8px 16px;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.9rem;
        display: inline-block;
        margin: 8px 4px;
    }
    
    .model-status {
        display: flex;
        gap: 1rem;
        justify-content: center;
        flex-wrap: wrap;
        margin: 1rem 0;
    }
    
    .model-badge {
        display: flex;
        align-items: center;
        gap: 6px;
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 0.85rem;
        font-weight: 600;
    }
    
    .model-active {
        background: linear-gradient(135deg, var(--primary-600), var(--primary-700));
        color: white;
    }
    
    .model-inactive {
        background: var(--gray-100);
        color: var(--gray-600);
    }
</style>
""", unsafe_allow_html=True)

def remove_tashkeel(text):
    """Remove Arabic diacritics"""
    if not isinstance(text, str):
        return ""
    tashkeel_pattern = re.compile(r'[\u064B-\u065F\u0670]')
    return tashkeel_pattern.sub('', text)

def preprocess_arabic_text(text):
    """Arabic text preprocessing"""
    if not isinstance(text, str):
        return ""
    
    text = remove_tashkeel(text)
    text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
    text = re.sub(r'Ø©', 'Ù‡', text)
    text = re.sub(r'ÙŠ', 'Ù‰', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def create_sample_data():
    """Create sample data"""
    sample_data = {
        'text': [
            'Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„ÙÙ‘Ù‡Ù Ø±ÙØ¨ÙÙ‘ Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù',
            'Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯ÙÙ‘ÙŠÙ†Ù',
            'Ø¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù',
            'Ø§Ù‡Ù’Ø¯ÙÙ†ÙØ§ Ø§Ù„ØµÙÙ‘Ø±ÙØ§Ø·Ù Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙÙ‚ÙÙŠÙ…Ù',
            'ØµÙØ±ÙØ§Ø·Ù Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø£ÙÙ†Ù’Ø¹ÙÙ…Ù’ØªÙ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ØºÙÙŠÙ’Ø±Ù Ø§Ù„Ù’Ù…ÙØºÙ’Ø¶ÙÙˆØ¨Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ÙˆÙÙ„ÙØ§ Ø§Ù„Ø¶ÙÙ‘Ø§Ù„ÙÙ‘ÙŠÙ†Ù',
            'Ø§Ù„Ù…',
            'Ø°ÙÙ°Ù„ÙÙƒÙ Ø§Ù„Ù’ÙƒÙØªÙØ§Ø¨Ù Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù Û› ÙÙÙŠÙ‡Ù Û› Ù‡ÙØ¯Ù‹Ù‰ Ù„ÙÙ‘Ù„Ù’Ù…ÙØªÙÙ‘Ù‚ÙÙŠÙ†Ù',
            'Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù Ø¨ÙØ§Ù„Ù’ØºÙÙŠÙ’Ø¨Ù ÙˆÙÙŠÙÙ‚ÙÙŠÙ…ÙÙˆÙ†Ù Ø§Ù„ØµÙÙ‘Ù„ÙØ§Ø©Ù ÙˆÙÙ…ÙÙ…ÙÙ‘Ø§ Ø±ÙØ²ÙÙ‚Ù’Ù†ÙØ§Ù‡ÙÙ…Ù’ ÙŠÙÙ†ÙÙÙ‚ÙÙˆÙ†Ù'
        ],
        'surah': ['Ø§Ù„ÙØ§ØªØ­Ø©'] * 7 + ['Ø§Ù„Ø¨Ù‚Ø±Ø©'] * 3,
        'ayah_number': [1, 2, 3, 4, 5, 6, 7, 1, 2, 3],
        'tafseer': [
            'Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ø§ÙØªØªØ§Ø­ ÙƒÙ„ Ø³ÙˆØ±Ø© Ø¨Ø­Ù…Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„ÙŠÙ‡',
            'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø±Ø¨ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠÙ†: Ø§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø¨ØµÙØ§ØªÙ‡ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø­Ø³Ù†Ù‰',
            'Ù…Ø§Ù„Ùƒ ÙŠÙˆÙ… Ø§Ù„Ø¯ÙŠÙ†: Ø§Ù„Ù„Ù‡ Ù‡Ùˆ Ø§Ù„Ù…Ø§Ù„Ùƒ Ø§Ù„Ù…ØªØµØ±Ù ÙŠÙˆÙ… Ø§Ù„Ù‚ÙŠØ§Ù…Ø©',
            'Ø¥ÙŠØ§Ùƒ Ù†Ø¹Ø¨Ø¯ ÙˆØ¥ÙŠØ§Ùƒ Ù†Ø³ØªØ¹ÙŠÙ†: Ø§Ù„ØªÙˆØ­ÙŠØ¯ ÙÙŠ Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ù†Ø©',
            'Ø§Ù‡Ø¯Ù†Ø§ Ø§Ù„ØµØ±Ø§Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…: Ø¯Ø¹Ø§Ø¡ Ø¨Ø§Ù„Ù‡Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…',
            'ØµØ±Ø§Ø· Ø§Ù„Ø°ÙŠÙ† Ø£Ù†Ø¹Ù…Øª Ø¹Ù„ÙŠÙ‡Ù…: Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡ ÙˆØ§Ù„ØµØ§Ù„Ø­ÙŠÙ†',
            'Ø§Ù„Ù…: Ù…Ù† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø·Ø¹Ø© ÙÙŠ Ø£ÙˆØ§Ø¦Ù„ Ø§Ù„Ø³ÙˆØ±',
            'Ø°Ù„Ùƒ Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ø§ Ø±ÙŠØ¨ ÙÙŠÙ‡: Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ù„Ø§ Ø´Ùƒ ÙÙŠÙ‡',
            'Ø§Ù„Ø°ÙŠÙ† ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ø§Ù„ØºÙŠØ¨: ØµÙØ© Ø§Ù„Ù…ØªÙ‚ÙŠÙ† Ø£Ù†Ù‡Ù… ÙŠØ¤Ù…Ù†ÙˆÙ† Ø¨Ù…Ø§ ØºØ§Ø¨ Ø¹Ù†Ù‡Ù…'
        ]
    }
    
    df = pd.DataFrame(sample_data)
    df['clean_text'] = df['text'].apply(preprocess_arabic_text)
    df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
    
    return df

@st.cache_data
def load_quran_dataset():
    """Load Quran dataset"""
    if not DATASETS_AVAILABLE:
        st.warning("âš ï¸ Ù…ÙƒØªØ¨Ø© datasets ØºÙŠØ± Ù…Ø«Ø¨ØªØ© - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
        return create_sample_data()
    
    try:
        with st.spinner("ğŸ“– Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†..."):
            dataset = load_dataset("MohamedRashad/Quran-Tafseer")
            
            if 'train' in dataset:
                df = pd.DataFrame(dataset['train'])
            else:
                split_name = list(dataset.keys())[0]
                df = pd.DataFrame(dataset[split_name])
            
            # Handle column mapping
            if 'ayah' in df.columns and 'text' not in df.columns:
                df['text'] = df['ayah']
            if 'verse' in df.columns and 'text' not in df.columns:
                df['text'] = df['verse']
            
            # Ensure required columns
            if 'text' not in df.columns:
                st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Øµ")
                return create_sample_data()
            
            if 'surah' not in df.columns:
                df['surah'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            if 'ayah_number' not in df.columns:
                df['ayah_number'] = range(1, len(df) + 1)
            if 'tafseer' not in df.columns:
                df['tafseer'] = ''
            
            # Clean data
            df['text'] = df['text'].fillna('').astype(str)
            df['tafseer'] = df['tafseer'].fillna('').astype(str)
            df['clean_text'] = df['text'].apply(preprocess_arabic_text)
            df['clean_tafseer'] = df['tafseer'].apply(preprocess_arabic_text)
            
            # Remove empty rows
            df = df[df['clean_text'].str.strip() != ''].copy()
            df = df.reset_index(drop=True)
            
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df):,} Ø¢ÙŠØ© Ù…Ù† Hugging Face")
            return df
            
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return create_sample_data()

def simple_text_search(query, df, top_k=10):
    """Simple text search"""
    try:
        clean_query = preprocess_arabic_text(query).lower()
        if not clean_query.strip():
            return pd.DataFrame(), []
        
        scores = []
        query_words = set(clean_query.split())
        
        for _, row in df.iterrows():
            text = preprocess_arabic_text(str(row['text'])).lower()
            tafseer = preprocess_arabic_text(str(row.get('tafseer', ''))).lower()
            combined_text = text + ' ' + tafseer
            text_words = set(combined_text.split())
            
            if query_words:
                overlap = len(query_words.intersection(text_words))
                score = overlap / len(query_words)
            else:
                score = 0
            
            scores.append(score)
        
        scores = np.array(scores)
        top_indices = scores.argsort()[-top_k:][::-1]
        top_scores = scores[top_indices]
        
        valid_mask = top_scores > 0
        if not np.any(valid_mask):
            return pd.DataFrame(), []
        
        top_indices = top_indices[valid_mask]
        top_scores = top_scores[valid_mask]
        
        result_df = df.iloc[top_indices].copy()
        return result_df, top_scores.tolist()
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
        return pd.DataFrame(), []

def tfidf_search(query, df, top_k=10):
    """TF-IDF search"""
    try:
        if not SKLEARN_AVAILABLE:
            return simple_text_search(query, df, top_k)
        
        clean_query = preprocess_arabic_text(query)
        if not clean_query.strip():
            return pd.DataFrame(), []
        
        texts = df['clean_text'].fillna('').tolist()
        if not texts:
            return pd.DataFrame(), []
        
        vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 3),
            min_df=1,
            max_df=0.95
        )
        
        corpus = [clean_query] + texts
        tfidf_matrix = vectorizer.fit_transform(corpus)
        query_vector = tfidf_matrix[0]
        document_vectors = tfidf_matrix[1:]
        
        similarities = cosine_similarity(query_vector, document_vectors).flatten()
        
        top_indices = similarities.argsort()[-top_k:][::-1]
        top_similarities = similarities[top_indices]
        
        valid_mask = top_similarities > 0.01
        if not np.any(valid_mask):
            return pd.DataFrame(), []
        
        top_indices = top_indices[valid_mask]
        top_similarities = top_similarities[valid_mask]
        
        result_df = df.iloc[top_indices].copy()
        return result_df, top_similarities.tolist()
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ: {e}")
        return simple_text_search(query, df, top_k)

def display_ayah_card(row, similarity_score=None, model_type=None, card_id=None):
    """Display ayah card"""
    if card_id is None:
        card_id = f"ayah_{hash(str(row.get('text', ''))[:50])}"
    
    with st.container():
        st.markdown('<div class="premium-card">', unsafe_allow_html=True)
        
        # Header
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            surah_name = row.get('surah', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            ayah_number = row.get('ayah_number', '')
            
            st.markdown(f"""
            <div class="surah-badge">ğŸ“– Ø³ÙˆØ±Ø© {surah_name}</div>
            <span class="ayah-number">{ayah_number}</span>
            """, unsafe_allow_html=True)
        
        with col2:
            if similarity_score is not None:
                percentage = int(similarity_score * 100)
                st.markdown(f"ğŸ¯ {percentage}%")
        
        with col3:
            if model_type:
                st.markdown(f"ğŸ” {model_type}")
        
        # Arabic text
        ayah_text = row.get('text', '')
        if ayah_text:
            st.markdown(f'<div class="premium-arabic">{ayah_text}</div>', unsafe_allow_html=True)
        
        # Tafseer
        tafseer_text = row.get('tafseer', '')
        if tafseer_text and tafseer_text.strip():
            st.markdown("**ğŸ“š Ø§Ù„ØªÙØ³ÙŠØ±:**")
            st.markdown(f'<div class="tafseer-text">{tafseer_text}</div>', unsafe_allow_html=True)
        
        # Action buttons
        st.markdown("---")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“š Ø­ÙØ¸", key=f"save_{card_id}", use_container_width=True):
                if 'saved_ayahs' not in st.session_state:
                    st.session_state.saved_ayahs = []
                st.session_state.saved_ayahs.append(ayah_text)
                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¢ÙŠØ©!")
        
        with col2:
            if st.button("ğŸ“‹ Ù†Ø³Ø®", key=f"copy_{card_id}", use_container_width=True):
                st.code(ayah_text, language="text")
                st.success("ğŸ“‹ ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø® Ø§Ù„Ù†Øµ Ø£Ø¹Ù„Ø§Ù‡!")
        
        st.markdown('</div>', unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state"""
    defaults = {
        'search_mode': 'tfidf',
        'saved_ayahs': [],
        'search_history': [],
        'daily_verses_read': 0,
        'total_verses_read': 0,
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def show_model_status():
    """Show model status"""
    st.markdown('<div class="model-status">', unsafe_allow_html=True)
    
    tfidf_class = "model-active" if SKLEARN_AVAILABLE else "model-inactive"
    tfidf_icon = "ğŸ“Š" if SKLEARN_AVAILABLE else "âŒ"
    st.markdown(f'<div class="model-badge {tfidf_class}"><span>{tfidf_icon}</span><span>TF-IDF</span></div>', unsafe_allow_html=True)
    
    st.markdown('<div class="model-badge model-active"><span>ğŸ”</span><span>Ø¨Ø­Ø« Ù†ØµÙŠ</span></div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def show_search_tab(df):
    """Search tab"""
    st.markdown("### ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ±")
    
    # Search mode selection
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š TF-IDF (Ø°ÙƒÙŠ)", 
                    disabled=not SKLEARN_AVAILABLE,
                    type="primary" if st.session_state.search_mode == 'tfidf' else "secondary",
                    use_container_width=True):
            st.session_state.search_mode = 'tfidf'
    
    with col2:
        if st.button("ğŸ” Ø¨Ø­Ø« Ù†ØµÙŠ", 
                    type="primary" if st.session_state.search_mode == 'simple' else "secondary",
                    use_container_width=True):
            st.session_state.search_mode = 'simple'
    
    # Search input
    col_search, col_button = st.columns([4, 1])
    
    with col_search:
        search_query = st.text_input(
            "",
            placeholder="Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ§Ù„ØªÙØ³ÙŠØ±... Ù…Ø«Ø§Ù„: 'Ø§Ù„ØµØ¨Ø±'ØŒ 'Ø§Ù„Ø±Ø­Ù…Ø©'ØŒ 'Ø§Ù„Ø¬Ù†Ø©'",
            key="main_search",
            label_visibility="collapsed"
        )
    
    with col_button:
        search_pressed = st.button("ğŸ” Ø¨Ø­Ø«", use_container_width=True)
    
    # Search options
    with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø«", expanded=False):
        max_results = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", 5, 50, 10)
        search_in_tafseer = st.checkbox("Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ± Ø£ÙŠØ¶Ø§Ù‹", value=True)
    
    # Perform search
    if search_query and (search_pressed or search_query):
        if search_query not in st.session_state.search_history:
            st.session_state.search_history.insert(0, search_query)
            st.session_state.search_history = st.session_state.search_history[:20]
        
        with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            search_df = df.copy()
            if search_in_tafseer:
                search_df['combined_text'] = (
                    search_df['clean_text'].fillna('') + ' ' + 
                    search_df.get('clean_tafseer', '').fillna('')
                )
                search_df['clean_text'] = search_df['combined_text']
            
            if st.session_state.search_mode == 'tfidf' and SKLEARN_AVAILABLE:
                results_df, similarities = tfidf_search(search_query, search_df, max_results)
                model_type = 'TF-IDF'
            else:
                results_df, similarities = simple_text_search(search_query, search_df, max_results)
                model_type = 'Ø¨Ø­Ø« Ù†ØµÙŠ'
            
            if not results_df.empty:
                st.success(f"ğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results_df)} Ù†ØªÙŠØ¬Ø©")
                
                if similarities:
                    avg_similarity = np.mean(similarities) * 100
                    max_similarity = np.max(similarities) * 100
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©", f"{avg_similarity:.1f}%")
                    with col2:
                        st.metric("Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø©", f"{max_similarity:.1f}%")
                    with col3:
                        unique_surahs = len(results_df['surah'].unique())
                        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
                
                for idx, (_, row) in enumerate(results_df.iterrows()):
                    similarity = similarities[idx] if idx < len(similarities) else None
                    display_ayah_card(row, similarity, model_type, f"result_{idx}")
                    
            else:
                st.markdown("""
                <div style="text-align: center; padding: 3rem; background: #f9fafb; border-radius: 20px; margin: 2rem 0;">
                    <div style="font-size: 3rem; margin-bottom: 1rem;">ğŸ”</div>
                    <h3>Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬</h3>
                    <p>Ø¬Ø±Ø¨ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ ØºÙŠØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«</p>
                </div>
                """, unsafe_allow_html=True)
    
    # Quick suggestions
    if not search_query:
        st.markdown("### ğŸš€ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
        
        suggestions = ["Ø§Ù„ØµØ¨Ø±", "Ø§Ù„Ø±Ø­Ù…Ø©", "Ø§Ù„Ø¬Ù†Ø©", "Ø§Ù„ØªÙˆØ¨Ø©", "Ø§Ù„Ø¯Ø¹Ø§Ø¡", "Ø§Ù„Ø¹Ø¯Ù„"]
        
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 3]:
                if st.button(f"ğŸ” {suggestion}", key=f"suggestion_{i}", use_container_width=True):
                    st.session_state.main_search = suggestion
                    st.rerun()

def show_saved_tab():
    """Saved ayahs tab"""
    st.markdown("### ğŸ“š Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
    
    if not st.session_state.saved_ayahs:
        st.markdown("""
        <div style="text-align: center; padding: 3rem; background: #f9fafb; border-radius: 20px; margin: 2rem 0;">
            <div style="font-size: 3rem; margin-bottom: 1rem;">ğŸ“š</div>
            <h3>Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¢ÙŠØ§Øª Ù…Ø­ÙÙˆØ¸Ø©</h3>
            <p>Ø§Ø­ÙØ¸ Ø¢ÙŠØ§ØªÙƒ Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«</p>
        </div>
        """, unsafe_allow_html=True)
        return
    
    st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", len(st.session_state.saved_ayahs))
    
    for i, ayah in enumerate(st.session_state.saved_ayahs):
        st.markdown(f"""
        <div class="premium-card">
            <div class="premium-arabic">{ayah}</div>
        </div>
        """, unsafe_allow_html=True)

def show_stats_tab(df):
    """Statistics tab"""
    st.markdown("### ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¢ÙŠØ§Øª", f"{len(df):,}")
    
    with col2:
        unique_surahs = len(df['surah'].unique())
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
    
    with col3:
        has_tafseer = len(df[df['tafseer'].notna() & (df['tafseer'] != '')])
        st.metric("Ø¢ÙŠØ§Øª Ø¨ØªÙØ³ÙŠØ±", f"{has_tafseer:,}")

def show_about_tab():
    """About tab"""
    st.markdown("### â„¹ï¸ Ø­ÙˆÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚")
    
    st.markdown("""
    **ğŸ¤– ØªØ·Ø¨ÙŠÙ‚ Ù…ØªØ·ÙˆØ± Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…**
    
    ÙŠØ³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ·ÙˆØ±Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… ÙˆØªÙØ³ÙŠØ±Ù‡:
    - **TF-IDF**: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª
    - **Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ**: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ Ø¨Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª
    - **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**: ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    
    **ğŸ“š Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** MohamedRashad/Quran-Tafseer Ø¹Ù„Ù‰ Hugging Face
    """)

def main():
    """Main application"""
    initialize_session_state()
    
    with st.spinner("ğŸš€ Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚..."):
        df = load_quran_dataset()
    
    if df.empty:
        st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†")
        st.stop()
    
    # Header
    st.markdown(f"""
    <div class="premium-header">
        <h1 class="header-title">ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</h1>
        <p style="font-size: 1.2rem; margin-bottom: 1rem;">Smart Quran Tafseer with AI Search</p>
        <p>Ø¨Ø­Ø« Ø°ÙƒÙŠ ÙÙŠ {len(df):,} Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ© Ù…Ø¹ Ø§Ù„ØªÙØ³ÙŠØ±</p>
    </div>
    """, unsafe_allow_html=True)
    
    show_model_status()
    
    # Navigation
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” Ø§Ù„Ø¨Ø­Ø«", "ğŸ“š Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", "ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "â„¹ï¸ Ø­ÙˆÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"])
    
    with tab1:
        show_search_tab(df)
    
    with tab2:
        show_saved_tab()
    
    with tab3:
        show_stats_tab(df)
    
    with tab4:
        show_about_tab()
    
    # Footer
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: var(--gray-500); padding: 2rem;">
        <p>ğŸ“– <strong>ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</strong> - ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ù€ â¤ï¸ Ù„Ø®Ø¯Ù…Ø© ÙƒØªØ§Ø¨ Ø§Ù„Ù„Ù‡</p>
        <p style="font-size: 0.9rem;">Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {datetime.now().strftime('%Y-%m-%d')}</p>
        <p style="font-size: 0.8rem;">Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: MohamedRashad/Quran-Tafseer Ø¹Ù„Ù‰ Hugging Face</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
