# requirements.txt for Streamlit Cloud
streamlit==1.28.0
pandas==1.5.3
numpy==1.24.0
scikit-learn==1.3.0
datasets==2.14.0
huggingface-hub==0.16.0

# Optional but recommended for better performance
joblib==1.3.0

# Note: Removed heavy dependencies that might cause deployment issues:
# - transformers (very large, comment out if not using BERT)
# - sentence-transformers (very large)
# - gensim (can be large)
# - torch (extremely large)

# For local development, you can uncomment these:
# transformers>=4.30.0
# sentence-transformers>=2.2.0
# gensim>=4.3.0

---

# .streamlit/config.toml
[server]
maxUploadSize = 200
enableCORS = false
enableXsrfProtection = false

[browser]
gatherUsageStats = false

[theme]
primaryColor = "#22c55e"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0fdf4"
textColor = "#1f2937"
font = "sans serif"

---

# packages.txt (system packages for Streamlit Cloud)
# Add any system-level dependencies here if needed
# For example:
# libgl1-mesa-glx
# libglib2.0-0

---

# Lightweight version of app.py for Streamlit Cloud deployment
# This version removes heavy ML dependencies and focuses on core functionality

import streamlit as st

# Page configuration MUST be first
st.set_page_config(
    page_title="ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ - Smart Quran Tafseer",
    page_icon="ğŸ“–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

import pandas as pd
import numpy as np
from datetime import datetime
import re
from collections import Counter

# Try to import optional dependencies with better error handling
PACKAGES_STATUS = {
    'datasets': False,
    'sklearn': False,
    'joblib': False
}

try:
    from datasets import load_dataset
    PACKAGES_STATUS['datasets'] = True
except ImportError:
    st.warning("âš ï¸ datasets package not available. Using fallback data.")

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    PACKAGES_STATUS['sklearn'] = True
except ImportError:
    st.warning("âš ï¸ scikit-learn not available. Limited search functionality.")

try:
    import joblib
    PACKAGES_STATUS['joblib'] = True
except ImportError:
    import pickle  # fallback

import warnings
warnings.filterwarnings('ignore')

# Lightweight CSS for Streamlit Cloud
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&family=Inter:wght@300;400;500;600;700&display=swap');
    
    :root {
        --primary-color: #22c55e;
        --secondary-color: #3b82f6;
        --accent-color: #f59e0b;
    }
    
    .main-header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        padding: 2rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .arabic-text {
        font-family: 'Amiri', serif;
        font-size: 1.5rem;
        line-height: 2;
        text-align: right;
        direction: rtl;
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-right: 4px solid var(--primary-color);
        margin: 1rem 0;
    }
    
    .verse-card {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        background: white;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .status-badge {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: bold;
        margin: 2px;
    }
    
    .status-active {
        background: #dcfce7;
        color: #166534;
    }
    
    .status-inactive {
        background: #fee2e2;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

def preprocess_arabic_text(text):
    """Lightweight Arabic text preprocessing"""
    if not isinstance(text, str):
        return ""
    
    # Remove diacritics
    tashkeel_pattern = re.compile(r'[\u064B-\u065F\u0670]')
    text = tashkeel_pattern.sub('', text)
    
    # Basic normalization
    text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
    text = re.sub(r'Ø©', 'Ù‡', text)
    text = re.sub(r'ÙŠ', 'Ù‰', text)
    
    # Clean whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    return text

@st.cache_data
def load_sample_data():
    """Create sample Quranic data for demonstration"""
    sample_verses = [
        {
            'text': 'Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'surah': 'Ø§Ù„ÙØ§ØªØ­Ø©',
            'ayah_number': 1,
            'tafseer': 'Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: Ø§Ø³ØªØ¹Ø§Ù†Ø© Ø¨Ø§Ù„Ù„Ù‡ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙƒÙ„ Ø¹Ù…Ù„'
        },
        {
            'text': 'Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„ÙÙ‘Ù‡Ù Ø±ÙØ¨ÙÙ‘ Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù',
            'surah': 'Ø§Ù„ÙØ§ØªØ­Ø©', 
            'ayah_number': 2,
            'tafseer': 'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡: Ø§Ù„Ø«Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø¨Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§Ù…Ø¯Ù‡'
        },
        {
            'text': 'Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù',
            'surah': 'Ø§Ù„ÙØ§ØªØ­Ø©',
            'ayah_number': 3,
            'tafseer': 'Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…: ØµÙØªØ§Ù† Ù…Ù† ØµÙØ§Øª Ø§Ù„Ù„Ù‡ ØªØ¯Ù„Ø§Ù† Ø¹Ù„Ù‰ Ø³Ø¹Ø© Ø±Ø­Ù…ØªÙ‡'
        },
        {
            'text': 'Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯ÙÙ‘ÙŠÙ†Ù',
            'surah': 'Ø§Ù„ÙØ§ØªØ­Ø©',
            'ayah_number': 4,
            'tafseer': 'Ù…Ø§Ù„Ùƒ ÙŠÙˆÙ… Ø§Ù„Ø¯ÙŠÙ†: Ø§Ù„Ù„Ù‡ Ø§Ù„Ù…Ø§Ù„Ùƒ Ø§Ù„Ù…ØªØµØ±Ù ÙŠÙˆÙ… Ø§Ù„Ø¬Ø²Ø§Ø¡'
        },
        {
            'text': 'Ø¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù',
            'surah': 'Ø§Ù„ÙØ§ØªØ­Ø©',
            'ayah_number': 5,
            'tafseer': 'Ø¥ÙŠØ§Ùƒ Ù†Ø¹Ø¨Ø¯ ÙˆØ¥ÙŠØ§Ùƒ Ù†Ø³ØªØ¹ÙŠÙ†: ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù„Ù‡ ÙÙŠ Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ù†Ø©'
        },
        {
            'text': 'Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙ Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø£ÙØ­ÙØ¯ÙŒ',
            'surah': 'Ø§Ù„Ø¥Ø®Ù„Ø§Øµ',
            'ayah_number': 1,
            'tafseer': 'Ù‚Ù„ Ù‡Ùˆ Ø§Ù„Ù„Ù‡ Ø£Ø­Ø¯: Ø¥Ø¹Ù„Ø§Ù† ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù„Ù‡ ÙˆØ£Ù†Ù‡ ÙˆØ§Ø­Ø¯ Ù„Ø§ Ø´Ø±ÙŠÙƒ Ù„Ù‡'
        },
        {
            'text': 'Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„ØµÙÙ‘Ù…ÙØ¯Ù',
            'surah': 'Ø§Ù„Ø¥Ø®Ù„Ø§Øµ',
            'ayah_number': 2,
            'tafseer': 'Ø§Ù„Ù„Ù‡ Ø§Ù„ØµÙ…Ø¯: Ø§Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ ÙŠØµÙ…Ø¯ Ø¥Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ø¦Ø¬'
        },
        {
            'text': 'ÙˆÙØ§Ù„Ù„ÙÙ‘ÙŠÙ’Ù„Ù Ø¥ÙØ°ÙØ§ ÙŠÙØºÙ’Ø´ÙÙ‰Ù°',
            'surah': 'Ø§Ù„Ù„ÙŠÙ„',
            'ayah_number': 1,
            'tafseer': 'ÙˆØ§Ù„Ù„ÙŠÙ„ Ø¥Ø°Ø§ ÙŠØºØ´Ù‰: Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„ÙŠÙ„ Ø¹Ù†Ø¯Ù…Ø§ ÙŠØºØ·ÙŠ Ø§Ù„Ø£Ø±Ø¶'
        },
        {
            'text': 'ÙˆÙØ§Ù„Ù†ÙÙ‘Ù‡ÙØ§Ø±Ù Ø¥ÙØ°ÙØ§ ØªÙØ¬ÙÙ„ÙÙ‘Ù‰Ù°',
            'surah': 'Ø§Ù„Ù„ÙŠÙ„',
            'ayah_number': 2,
            'tafseer': 'ÙˆØ§Ù„Ù†Ù‡Ø§Ø± Ø¥Ø°Ø§ ØªØ¬Ù„Ù‰: Ù‚Ø³Ù… Ø¨Ø§Ù„Ù†Ù‡Ø§Ø± Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ¸Ù‡Ø± ÙˆÙŠØ¶ÙŠØ¡'
        },
        {
            'text': 'Ø±ÙØ¨ÙÙ‘Ù†ÙØ§ Ø¢ØªÙÙ†ÙØ§ ÙÙÙŠ Ø§Ù„Ø¯ÙÙ‘Ù†Ù’ÙŠÙØ§ Ø­ÙØ³ÙÙ†ÙØ©Ù‹ ÙˆÙÙÙÙŠ Ø§Ù„Ù’Ø¢Ø®ÙØ±ÙØ©Ù Ø­ÙØ³ÙÙ†ÙØ©Ù‹ ÙˆÙÙ‚ÙÙ†ÙØ§ Ø¹ÙØ°ÙØ§Ø¨Ù Ø§Ù„Ù†ÙÙ‘Ø§Ø±Ù',
            'surah': 'Ø§Ù„Ø¨Ù‚Ø±Ø©',
            'ayah_number': 201,
            'tafseer': 'Ø¯Ø¹Ø§Ø¡ Ø¬Ø§Ù…Ø¹ Ù„Ù„Ø®ÙŠØ± ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø¢Ø®Ø±Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ø°Ø© Ù…Ù† Ø§Ù„Ù†Ø§Ø±'
        }
    ]
    
    df = pd.DataFrame(sample_verses)
    df['clean_text'] = df['text'].apply(preprocess_arabic_text)
    return df

@st.cache_data
def load_quran_data():
    """Load Quran data with fallback to sample data"""
    if not PACKAGES_STATUS['datasets']:
        st.info("ğŸ“± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© - Ø«Ø¨Øª Ù…ÙƒØªØ¨Ø© datasets Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
        return load_sample_data()
    
    try:
        with st.spinner("ğŸ“– Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†..."):
            # Try to load from Hugging Face
            dataset = load_dataset("MohamedRashad/Quran-Tafseer", split="train")
            df = pd.DataFrame(dataset)
            
            # Handle different column names
            if 'ayah' in df.columns and 'text' not in df.columns:
                df['text'] = df['ayah']
            elif 'verse' in df.columns and 'text' not in df.columns:
                df['text'] = df['verse']
            
            # Ensure required columns
            required_columns = ['text', 'surah', 'ayah_number']
            for col in required_columns:
                if col not in df.columns:
                    if col == 'surah':
                        df['surah'] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                    elif col == 'ayah_number':
                        df['ayah_number'] = range(1, len(df) + 1)
            
            # Add tafseer if not present
            if 'tafseer' not in df.columns:
                df['tafseer'] = ''
            
            df['clean_text'] = df['text'].apply(preprocess_arabic_text)
            
            # Limit dataset size for demo (remove for production)
            if len(df) > 1000:
                df = df.head(1000)  # Limit to first 1000 verses for demo
            
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø¢ÙŠØ©")
            return df
            
    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        st.info("ğŸ”„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
        return load_sample_data()

def simple_search(query, df, max_results=10):
    """Simple text search without ML dependencies"""
    if not query or df.empty:
        return pd.DataFrame(), []
    
    query_clean = preprocess_arabic_text(query).lower()
    query_words = set(query_clean.split())
    
    if not query_words:
        return pd.DataFrame(), []
    
    scores = []
    for _, row in df.iterrows():
        text_clean = preprocess_arabic_text(str(row['text'])).lower()
        text_words = set(text_clean.split())
        
        # Calculate Jaccard similarity
        intersection = len(query_words & text_words)
        union = len(query_words | text_words)
        
        if union > 0:
            score = intersection / union
        else:
            score = 0
        
        scores.append(score)
    
    # Get top results
    df_with_scores = df.copy()
    df_with_scores['score'] = scores
    
    # Filter and sort
    results = df_with_scores[df_with_scores['score'] > 0].nlargest(max_results, 'score')
    
    return results.drop('score', axis=1), results['score'].tolist()

def tfidf_search(query, df, max_results=10):
    """TF-IDF search if sklearn is available"""
    if not PACKAGES_STATUS['sklearn']:
        return simple_search(query, df, max_results)
    
    try:
        texts = [preprocess_arabic_text(query)] + df['clean_text'].tolist()
        
        vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            min_df=1,
            max_df=0.95
        )
        
        tfidf_matrix = vectorizer.fit_transform(texts)
        query_vector = tfidf_matrix[0]
        doc_vectors = tfidf_matrix[1:]
        
        similarities = cosine_similarity(query_vector, doc_vectors).flatten()
        
        # Get top results
        top_indices = similarities.argsort()[-max_results:][::-1]
        top_scores = similarities[top_indices]
        
        # Filter by minimum similarity
        valid_mask = top_scores > 0.01
        if not valid_mask.any():
            return pd.DataFrame(), []
        
        top_indices = top_indices[valid_mask]
        top_scores = top_scores[valid_mask]
        
        return df.iloc[top_indices], top_scores.tolist()
        
    except Exception as e:
        st.warning(f"TF-IDF search failed: {e}")
        return simple_search(query, df, max_results)

def display_verse_card(verse_data, score=None):
    """Display a verse in a nice card format"""
    with st.container():
        st.markdown('<div class="verse-card">', unsafe_allow_html=True)
        
        # Header with surah info and score
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown(f"**ğŸ“– Ø³ÙˆØ±Ø© {verse_data['surah']} - Ø¢ÙŠØ© {verse_data['ayah_number']}**")
        
        with col2:
            if score is not None:
                percentage = int(score * 100)
                st.markdown(f"ğŸ¯ **{percentage}%**")
        
        # Arabic text
        st.markdown(f'<div class="arabic-text">{verse_data["text"]}</div>', 
                   unsafe_allow_html=True)
        
        # Tafseer if available
        if verse_data.get('tafseer') and verse_data['tafseer'].strip():
            st.markdown("**ğŸ“š Ø§Ù„ØªÙØ³ÙŠØ±:**")
            st.markdown(f"*{verse_data['tafseer']}*")
        
        st.markdown('</div>', unsafe_allow_html=True)

def show_package_status():
    """Show status of available packages"""
    st.markdown("### ğŸ“¦ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status = "active" if PACKAGES_STATUS['datasets'] else "inactive"
        icon = "âœ…" if PACKAGES_STATUS['datasets'] else "âŒ"
        st.markdown(f'<span class="status-badge status-{status}">{icon} Datasets</span>', 
                   unsafe_allow_html=True)
    
    with col2:
        status = "active" if PACKAGES_STATUS['sklearn'] else "inactive"
        icon = "âœ…" if PACKAGES_STATUS['sklearn'] else "âŒ"
        st.markdown(f'<span class="status-badge status-{status}">{icon} Scikit-learn</span>', 
                   unsafe_allow_html=True)
    
    with col3:
        status = "active" if PACKAGES_STATUS['joblib'] else "inactive"
        icon = "âœ…" if PACKAGES_STATUS['joblib'] else "âŒ"
        st.markdown(f'<span class="status-badge status-{status}">{icon} Joblib</span>', 
                   unsafe_allow_html=True)

def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“– ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</h1>
        <p>Smart Quran Tafseer - Cloud Version</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Load data
    df = load_quran_data()
    
    if df.empty:
        st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        st.stop()
    
    # Show package status
    show_package_status()
    
    # Search interface
    st.markdown("### ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…")
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "",
            placeholder="Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†... Ù…Ø«Ø§Ù„: Ø§Ù„Ø±Ø­Ù…Ø©ØŒ Ø§Ù„ØµØ¨Ø±ØŒ Ø§Ù„Ø¬Ù†Ø©",
            label_visibility="collapsed"
        )
    
    with col2:
        search_method = st.selectbox(
            "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø­Ø«",
            ["Ø°ÙƒÙŠ" if PACKAGES_STATUS['sklearn'] else "Ù†ØµÙŠ Ø¨Ø³ÙŠØ·", "Ù†ØµÙŠ Ø¨Ø³ÙŠØ·"]
        )
    
    # Advanced options
    with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"):
        max_results = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", 5, 50, 10)
        search_in_tafseer = st.checkbox("Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ± Ø£ÙŠØ¶Ø§Ù‹", value=True)
    
    # Perform search
    if search_query:
        with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            # Prepare search dataframe
            search_df = df.copy()
            if search_in_tafseer:
                # Combine text and tafseer for search
                search_df['combined_text'] = (
                    search_df['clean_text'].fillna('') + ' ' + 
                    search_df['tafseer'].fillna('').apply(preprocess_arabic_text)
                )
                search_df['clean_text'] = search_df['combined_text']
            
            # Execute search
            if search_method == "Ø°ÙƒÙŠ" and PACKAGES_STATUS['sklearn']:
                results_df, scores = tfidf_search(search_query, search_df, max_results)
                search_type = "TF-IDF Ø°ÙƒÙŠ"
            else:
                results_df, scores = simple_search(search_query, search_df, max_results)
                search_type = "Ù†ØµÙŠ Ø¨Ø³ÙŠØ·"
            
            # Display results
            if not results_df.empty:
                st.success(f"ğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results_df)} Ù†ØªÙŠØ¬Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø­Ø« {search_type}")
                
                # Show average score
                if scores:
                    avg_score = np.mean(scores) * 100
                    st.info(f"ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {avg_score:.1f}%")
                
                # Display verses
                for idx, (_, verse) in enumerate(results_df.iterrows()):
                    score = scores[idx] if idx < len(scores) else None
                    display_verse_card(verse, score)
                    
            else:
                st.warning("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬. Ø¬Ø±Ø¨ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©.")
    
    # Quick suggestions
    if not search_query:
        st.markdown("### ğŸš€ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
        
        suggestions = ["Ø§Ù„Ø±Ø­Ù…Ø©", "Ø§Ù„ØµØ¨Ø±", "Ø§Ù„Ø¬Ù†Ø©", "Ø§Ù„ØªÙˆØ¨Ø©", "Ø§Ù„Ø¯Ø¹Ø§Ø¡", "Ø§Ù„Ø¹Ø¯Ù„"]
        
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 3]:
                if st.button(f"ğŸ” {suggestion}", key=f"suggestion_{i}"):
                    st.session_state.search_query = suggestion
                    st.experimental_rerun()
    
    # Statistics
    st.markdown("### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¢ÙŠØ§Øª", len(df))
    
    with col2:
        unique_surahs = len(df['surah'].unique())
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙˆØ±", unique_surahs)
    
    with col3:
        avg_length = df['text'].str.len().mean()
        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ©", f"{avg_length:.0f} Ø­Ø±Ù")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p>ğŸ“– <strong>ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø°ÙƒÙŠ</strong> - Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ø³Ø­Ø§Ø¨Ø©</p>
        <p style="font-size: 0.9rem;">Ù„Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø­Ù„ÙŠØ§Ù‹</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
